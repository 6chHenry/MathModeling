<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/enhanced_neural_predictor.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/enhanced_neural_predictor.py" />
              <option name="originalContent" value="import pandas as pd&#10;import numpy as np&#10;import matplotlib.pyplot as plt&#10;import seaborn as sns&#10;import torch&#10;import torch.nn as nn&#10;import torch.optim as optim&#10;from torch.utils.data import Dataset, DataLoader&#10;from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler&#10;from sklearn.model_selection import train_test_split, KFold&#10;from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error&#10;from sklearn.feature_extraction.text import TfidfVectorizer&#10;import warnings&#10;warnings.filterwarnings('ignore')&#10;&#10;# 设置中文字体&#10;plt.rcParams['font.sans-serif'] = ['SimHei']&#10;plt.rcParams['axes.unicode_minus'] = False&#10;&#10;# 设置随机种子确保可复现性&#10;torch.manual_seed(42)&#10;np.random.seed(42)&#10;if torch.cuda.is_available():&#10;    torch.cuda.manual_seed(42)&#10;&#10;class MovieDataset(Dataset):&#10;    &quot;&quot;&quot;电影数据集类&quot;&quot;&quot;&#10;    def __init__(self, features, targets=None):&#10;        self.features = torch.FloatTensor(features)&#10;        self.targets = torch.FloatTensor(targets) if targets is not None else None&#10;&#10;    def __len__(self):&#10;        return len(self.features)&#10;&#10;    def __getitem__(self, idx):&#10;        if self.targets is not None:&#10;            return self.features[idx], self.targets[idx]&#10;        return self.features[idx]&#10;&#10;class AdvancedMovieRatingNN(nn.Module):&#10;    &quot;&quot;&quot;增强的电影评分预测神经网络&quot;&quot;&quot;&#10;    def __init__(self, input_dim, hidden_dims=[1024, 512, 256, 128], dropout_rate=0.3):&#10;        super(AdvancedMovieRatingNN, self).__init__()&#10;&#10;        layers = []&#10;        prev_dim = input_dim&#10;&#10;        # 输入层归一化&#10;        layers.append(nn.BatchNorm1d(input_dim))&#10;&#10;        # 构建隐藏层&#10;        for i, hidden_dim in enumerate(hidden_dims):&#10;            layers.extend([&#10;                nn.Linear(prev_dim, hidden_dim),&#10;                nn.BatchNorm1d(hidden_dim),&#10;                nn.LeakyReLU(0.1),  # 使用LeakyReLU防止死神经元&#10;                nn.Dropout(dropout_rate * (0.8 ** i))  # 递减的dropout&#10;            ])&#10;            prev_dim = hidden_dim&#10;&#10;        # 输出层&#10;        layers.extend([&#10;            nn.Linear(prev_dim, 64),&#10;            nn.ReLU(),&#10;            nn.Dropout(0.1),&#10;            nn.Linear(64, 1),&#10;            nn.Sigmoid()  # 输出0-1，后续映射到1-10&#10;        ])&#10;&#10;        self.network = nn.Sequential(*layers)&#10;&#10;        # 权重初始化&#10;        self.apply(self._init_weights)&#10;&#10;    def _init_weights(self, m):&#10;        if isinstance(m, nn.Linear):&#10;            torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')&#10;            torch.nn.init.zeros_(m.bias)&#10;&#10;    def forward(self, x):&#10;        output = self.network(x)&#10;        # 将输出从[0,1]映射到[1,10]&#10;        return output.squeeze() * 9 + 1&#10;&#10;class EarlyStopping:&#10;    &quot;&quot;&quot;早停机制&quot;&quot;&quot;&#10;    def __init__(self, patience=15, min_delta=0.001):&#10;        self.patience = patience&#10;        self.min_delta = min_delta&#10;        self.counter = 0&#10;        self.best_loss = float('inf')&#10;        self.early_stop = False&#10;&#10;    def __call__(self, val_loss):&#10;        if val_loss &lt; self.best_loss - self.min_delta:&#10;            self.best_loss = val_loss&#10;            self.counter = 0&#10;        else:&#10;            self.counter += 1&#10;            if self.counter &gt;= self.patience:&#10;                self.early_stop = True&#10;&#10;class EnhancedMovieRatingPredictor:&#10;    def __init__(self):&#10;        self.model = None&#10;        self.scaler = StandardScaler()&#10;        self.target_scaler = MinMaxScaler(feature_range=(0, 1))  # 目标值归一化&#10;        self.label_encoders = {}&#10;        self.tfidf_vectorizers = {}&#10;        self.feature_names = []&#10;        self.training_history = {&#10;            'train_loss': [], 'val_loss': [], 'train_r2': [], 'val_r2': []&#10;        }&#10;        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')&#10;        print(f&quot;使用设备: {self.device}&quot;)&#10;&#10;    def load_data(self):&#10;        &quot;&quot;&quot;加载数据&quot;&quot;&quot;&#10;        print(&quot;正在加载数据...&quot;)&#10;&#10;        # 加载测试数据&#10;        test_df = pd.read_csv('input_data/df_movies_test.csv')&#10;        print(f&quot;测试数据形状: {test_df.shape}&quot;)&#10;&#10;        # 加载训练数据&#10;        try:&#10;            train_df = pd.read_csv('df_movies_cleaned.csv')&#10;            print(f&quot;训练数据形状: {train_df.shape}&quot;)&#10;            # 修改这里：使用正确的列名&#10;            print(f&quot;评分范围: {train_df['rating'].min():.2f} - {train_df['rating'].max():.2f}&quot;)&#10;            print(f&quot;评分分布:\n{train_df['rating'].describe()}&quot;)&#10;        except Exception as e:&#10;            print(f&quot;无法读取训练数据: {e}&quot;)&#10;            return None, None&#10;&#10;        return train_df, test_df&#10;&#10;    def comprehensive_feature_engineering(self, df, is_train=True):&#10;        &quot;&quot;&quot;综合特征工程&quot;&quot;&quot;&#10;        df = df.copy()&#10;        print(f&quot;特征工程 - 输入数据形状: {df.shape}&quot;)&#10;&#10;        # 1. 处理类型特征&#10;        if 'genres' in df.columns:&#10;            df['genres'] = df['genres'].fillna('Unknown')&#10;&#10;            # TF-IDF向量化&#10;            genres_text = df['genres'].str.replace(',', ' ')&#10;            if is_train:&#10;                self.tfidf_vectorizers['genres'] = TfidfVectorizer(&#10;                    max_features=30, stop_words=None, lowercase=True, min_df=1&#10;                )&#10;                genres_tfidf = self.tfidf_vectorizers['genres'].fit_transform(genres_text).toarray()&#10;            else:&#10;                genres_tfidf = self.tfidf_vectorizers['genres'].transform(genres_text).toarray()&#10;&#10;            # 添加TF-IDF特征&#10;            for i in range(genres_tfidf.shape[1]):&#10;                df[f'genre_tfidf_{i}'] = genres_tfidf[:, i]&#10;&#10;            # 基础特征&#10;            df['genre_count'] = df['genres'].str.count(',') + 1&#10;            df['is_action'] = df['genres'].str.contains('Action', na=False).astype(int)&#10;            df['is_drama'] = df['genres'].str.contains('Drama', na=False).astype(int)&#10;            df['is_comedy'] = df['genres'].str.contains('Comedy', na=False).astype(int)&#10;            df['is_thriller'] = df['genres'].str.contains('Thriller', na=False).astype(int)&#10;            df['is_romance'] = df['genres'].str.contains('Romance', na=False).astype(int)&#10;&#10;        # 2. 处理演员特征&#10;        if 'cast' in df.columns:&#10;            df['cast'] = df['cast'].fillna('Unknown')&#10;&#10;            # 演员TF-IDF&#10;            cast_text = df['cast'].str.replace(',', ' ')&#10;            if is_train:&#10;                self.tfidf_vectorizers['cast'] = TfidfVectorizer(&#10;                    max_features=50, stop_words=None, lowercase=True, min_df=1&#10;                )&#10;                cast_tfidf = self.tfidf_vectorizers['cast'].fit_transform(cast_text).toarray()&#10;            else:&#10;                cast_tfidf = self.tfidf_vectorizers['cast'].transform(cast_text).toarray()&#10;&#10;            for i in range(cast_tfidf.shape[1]):&#10;                df[f'cast_tfidf_{i}'] = cast_tfidf[:, i]&#10;&#10;            df['cast_count'] = df['cast'].str.count(',') + 1&#10;&#10;        # 3. 处理导演特征 - 修复Unknown标签错误&#10;        if 'director' in df.columns:&#10;            df['director'] = df['director'].fillna('Unknown')&#10;            df['has_director'] = (df['director'] != 'Unknown').astype(int)&#10;&#10;            if is_train:&#10;                # 训练时拟合编码器&#10;                unique_directors = df['director'].unique()&#10;                self.label_encoders['director'] = LabelEncoder()&#10;                self.label_encoders['director'].fit(unique_directors)&#10;                df['director_encoded'] = self.label_encoders['director'].transform(df['director'])&#10;            else:&#10;                # 测试时处理未见过的导演&#10;                known_directors = set(self.label_encoders['director'].classes_)&#10;                df['director_mapped'] = df['director'].apply(&#10;                    lambda x: x if x in known_directors else 'Unknown'&#10;                )&#10;                df['director_encoded'] = self.label_encoders['director'].transform(df['director_mapped'])&#10;&#10;        # 4. 处理编剧特征&#10;        if 'writers' in df.columns:&#10;            df['writers'] = df['writers'].fillna('Unknown')&#10;            df['writers_count'] = df['writers'].str.count(',') + 1&#10;            df['has_writers'] = (df['writers'] != 'Unknown').astype(int)&#10;&#10;        # 5. 处理制片公司特征&#10;        if 'production_companies' in df.columns:&#10;            df['production_companies'] = df['production_companies'].fillna('Unknown')&#10;            df['production_count'] = df['production_companies'].str.count(',') + 1&#10;            df['has_production'] = (df['production_companies'] != 'Unknown').astype(int)&#10;&#10;        # 6. 处理制片人特征&#10;        if 'producers' in df.columns:&#10;            df['producers'] = df['producers'].fillna('Unknown')&#10;            df['producers_count'] = df['producers'].str.count(',') + 1&#10;            df['has_producers'] = (df['producers'] != 'Unknown').astype(int)&#10;&#10;        # 7. 处理语言特征&#10;        if 'original_language' in df.columns:&#10;            df['original_language'] = df['original_language'].fillna('Unknown')&#10;&#10;            if is_train:&#10;                unique_languages = df['original_language'].unique()&#10;                self.label_encoders['language'] = LabelEncoder()&#10;                self.label_encoders['language'].fit(unique_languages)&#10;                df['language_encoded'] = self.label_encoders['language'].transform(df['original_language'])&#10;            else:&#10;                known_languages = set(self.label_encoders['language'].classes_)&#10;                df['language_mapped'] = df['original_language'].apply(&#10;                    lambda x: x if x in known_languages else 'Unknown'&#10;                )&#10;                df['language_encoded'] = self.label_encoders['language'].transform(df['language_mapped'])&#10;&#10;            # 语言特征&#10;            df['is_english'] = (df['original_language'] == 'EN').astype(int)&#10;            df['is_mandarin'] = (df['original_language'] == 'Mandarin').astype(int)&#10;&#10;        # 8. 处理时长特征&#10;        if 'runtime' in df.columns:&#10;            df['runtime'] = df['runtime'].fillna(df['runtime'].median() if is_train else 120)&#10;&#10;            # 时长分类&#10;            df['runtime_short'] = (df['runtime'] &lt;= 90).astype(int)&#10;            df['runtime_normal'] = ((df['runtime'] &gt; 90) &amp; (df['runtime'] &lt;= 150)).astype(int)&#10;            df['runtime_long'] = (df['runtime'] &gt; 150).astype(int)&#10;&#10;            # 时长变换&#10;            df['runtime_log'] = np.log1p(df['runtime'])&#10;            df['runtime_sqrt'] = np.sqrt(df['runtime'])&#10;&#10;        # 9. 交互特征&#10;        if 'cast_count' in df.columns and 'runtime' in df.columns:&#10;            df['cast_runtime_ratio'] = df['cast_count'] / (df['runtime'] + 1)&#10;            df['cast_density'] = df['cast_count'] / np.log1p(df['runtime'])&#10;&#10;        if 'writers_count' in df.columns and 'production_count' in df.columns:&#10;            df['creative_team_size'] = df['writers_count'] + df['production_count']&#10;            df['production_complexity'] = df['writers_count'] * df['production_count']&#10;&#10;        # 10. 统计特征&#10;        numeric_cols = ['genre_count', 'cast_count', 'writers_count', 'production_count', 'runtime']&#10;        for col in numeric_cols:&#10;            if col in df.columns:&#10;                df[f'{col}_normalized'] = (df[col] - df[col].min()) / (df[col].max() - df[col].min() + 1e-8)&#10;&#10;        print(f&quot;特征工程后数据形状: {df.shape}&quot;)&#10;        return df&#10;&#10;    def prepare_features(self, df, is_train=True):&#10;        &quot;&quot;&quot;准备训练特征&quot;&quot;&quot;&#10;        # 选择数值特征&#10;        feature_cols = []&#10;&#10;        # TF-IDF特征&#10;        tfidf_cols = [col for col in df.columns if 'tfidf' in col]&#10;        feature_cols.extend(tfidf_cols)&#10;&#10;        # 数值特征&#10;        numeric_features = [&#10;            'genre_count', 'cast_count', 'writers_count', 'production_count',&#10;            'runtime', 'runtime_log', 'runtime_sqrt',&#10;            'director_encoded', 'language_encoded',&#10;            'cast_runtime_ratio', 'cast_density', 'creative_team_size', 'production_complexity'&#10;        ]&#10;&#10;        # 二进制特征&#10;        binary_features = [&#10;            'has_director', 'has_writers', 'has_production', 'has_producers',&#10;            'runtime_short', 'runtime_normal', 'runtime_long',&#10;            'is_action', 'is_drama', 'is_comedy', 'is_thriller', 'is_romance',&#10;            'is_english', 'is_mandarin'&#10;        ]&#10;&#10;        # 归一化特征&#10;        normalized_features = [col for col in df.columns if col.endswith('_normalized')]&#10;&#10;        # 合并所有特征&#10;        all_features = numeric_features + binary_features + normalized_features&#10;        available_features = [col for col in all_features if col in df.columns]&#10;        feature_cols.extend(available_features)&#10;&#10;        # 去重&#10;        feature_cols = list(set(feature_cols))&#10;&#10;        if is_train:&#10;            self.feature_names = feature_cols&#10;&#10;        print(f&quot;使用 {len(feature_cols)} 个特征进行训练&quot;)&#10;&#10;        # 提取特征矩阵&#10;        X = df[feature_cols].values&#10;&#10;        # 处理无穷大和NaN&#10;        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)&#10;&#10;        return X&#10;&#10;    def train_with_cross_validation(self, X, y, n_splits=5, epochs=200, batch_size=64, learning_rate=0.001):&#10;        &quot;&quot;&quot;使用交叉验证训练模型&quot;&quot;&quot;&#10;        print(f&quot;开始交叉验证训练，数据形状: X={X.shape}, y={y.shape}&quot;)&#10;&#10;        kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)&#10;        cv_scores = []&#10;&#10;        for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):&#10;            print(f&quot;\n=== 第 {fold+1} 折交叉验证 ===&quot;)&#10;&#10;            X_train_fold, X_val_fold = X[train_idx], X[val_idx]&#10;            y_train_fold, y_val_fold = y[train_idx], y[val_idx]&#10;&#10;            # 标准化特征&#10;            fold_scaler = StandardScaler()&#10;            X_train_scaled = fold_scaler.fit_transform(X_train_fold)&#10;            X_val_scaled = fold_scaler.transform(X_val_fold)&#10;&#10;            # 创建数据加载器&#10;            train_dataset = MovieDataset(X_train_scaled, y_train_fold)&#10;            val_dataset = MovieDataset(X_val_scaled, y_val_fold)&#10;&#10;            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)&#10;            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)&#10;&#10;            # 创建模型&#10;            model = AdvancedMovieRatingNN(X.shape[1]).to(self.device)&#10;            optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)&#10;            scheduler = optim.lr_scheduler.ReduceLROnPlateau(&#10;                optimizer, mode='min', factor=0.8, patience=10&#10;            )&#10;            criterion = nn.MSELoss()&#10;&#10;            # 训练模型&#10;            best_val_loss = float('inf')&#10;            for epoch in range(epochs):&#10;                # 训练阶段&#10;                model.train()&#10;                train_losses = []&#10;                for batch_X, batch_y in train_loader:&#10;                    batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)&#10;&#10;                    optimizer.zero_grad()&#10;                    outputs = model(batch_X)&#10;                    loss = criterion(outputs, batch_y)&#10;                    loss.backward()&#10;                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)&#10;                    optimizer.step()&#10;&#10;                    train_losses.append(loss.item())&#10;&#10;                # 验证阶段&#10;                model.eval()&#10;                val_losses = []&#10;                with torch.no_grad():&#10;                    for batch_X, batch_y in val_loader:&#10;                        batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)&#10;                        outputs = model(batch_X)&#10;                        loss = criterion(outputs, batch_y)&#10;                        val_losses.append(loss.item())&#10;&#10;                avg_train_loss = np.mean(train_losses)&#10;                avg_val_loss = np.mean(val_losses)&#10;                scheduler.step(avg_val_loss)&#10;&#10;                if avg_val_loss &lt; best_val_loss:&#10;                    best_val_loss = avg_val_loss&#10;&#10;                if epoch % 20 == 0:&#10;                    print(f&quot;Epoch {epoch:3d}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}&quot;)&#10;&#10;            # 计算最终验证分数&#10;            model.eval()&#10;            with torch.no_grad():&#10;                val_predictions = []&#10;                for batch_X, _ in val_loader:&#10;                    batch_X = batch_X.to(self.device)&#10;                    outputs = model(batch_X)&#10;                    val_predictions.extend(outputs.cpu().numpy())&#10;&#10;            val_r2 = r2_score(y_val_fold, val_predictions)&#10;            cv_scores.append(val_r2)&#10;            print(f&quot;第 {fold+1} 折 R2 分数: {val_r2:.4f}&quot;)&#10;&#10;        print(f&quot;\n交叉验证平均 R2 分数: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}&quot;)&#10;        return np.mean(cv_scores)&#10;&#10;    def train(self, X, y, validation_split=0.2, epochs=300, batch_size=64, learning_rate=0.001):&#10;        &quot;&quot;&quot;训练模型&quot;&quot;&quot;&#10;        print(f&quot;开始训练，数据形状: X={X.shape}, y={y.shape}&quot;)&#10;        print(f&quot;目标值范围: {y.min():.2f} - {y.max():.2f}&quot;)&#10;&#10;        # 划分训练集和验证集&#10;        X_train, X_val, y_train, y_val = train_test_split(&#10;            X, y, test_size=validation_split, random_state=42, stratify=None&#10;        )&#10;&#10;        # 标准化特征&#10;        X_train_scaled = self.scaler.fit_transform(X_train)&#10;        X_val_scaled = self.scaler.transform(X_val)&#10;&#10;        print(f&quot;训练集大小: {X_train_scaled.shape[0]}, 验证集大小: {X_val_scaled.shape[0]}&quot;)&#10;&#10;        # 创建数据加载器&#10;        train_dataset = MovieDataset(X_train_scaled, y_train)&#10;        val_dataset = MovieDataset(X_val_scaled, y_val)&#10;&#10;        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)&#10;        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)&#10;&#10;        # 创建模型&#10;        self.model = AdvancedMovieRatingNN(X.shape[1]).to(self.device)&#10;&#10;        # 优化器和调度器&#10;        optimizer = optim.AdamW(&#10;            self.model.parameters(),&#10;            lr=learning_rate,&#10;            weight_decay=0.01,&#10;            betas=(0.9, 0.999)&#10;        )&#10;&#10;        scheduler = optim.lr_scheduler.ReduceLROnPlateau(&#10;            optimizer, mode='min', factor=0.8, patience=15, verbose=True, min_lr=1e-6&#10;        )&#10;&#10;        criterion = nn.MSELoss()&#10;        early_stopping = EarlyStopping(patience=25, min_delta=0.001)&#10;&#10;        print(&quot;开始训练...&quot;)&#10;        best_val_loss = float('inf')&#10;&#10;        for epoch in range(epochs):&#10;            # 训练阶段&#10;            self.model.train()&#10;            train_losses = []&#10;            train_predictions = []&#10;            train_targets = []&#10;&#10;            for batch_X, batch_y in train_loader:&#10;                batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)&#10;&#10;                optimizer.zero_grad()&#10;                outputs = self.model(batch_X)&#10;                loss = criterion(outputs, batch_y)&#10;                loss.backward()&#10;&#10;                # 梯度裁剪&#10;                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)&#10;                optimizer.step()&#10;&#10;                train_losses.append(loss.item())&#10;                train_predictions.extend(outputs.cpu().detach().numpy())&#10;                train_targets.extend(batch_y.cpu().numpy())&#10;&#10;            # 验证阶段&#10;            self.model.eval()&#10;            val_losses = []&#10;            val_predictions = []&#10;            val_targets = []&#10;&#10;            with torch.no_grad():&#10;                for batch_X, batch_y in val_loader:&#10;                    batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)&#10;                    outputs = self.model(batch_X)&#10;                    loss = criterion(outputs, batch_y)&#10;&#10;                    val_losses.append(loss.item())&#10;                    val_predictions.extend(outputs.cpu().numpy())&#10;                    val_targets.extend(batch_y.cpu().numpy())&#10;&#10;            # 计算指标&#10;            avg_train_loss = np.mean(train_losses)&#10;            avg_val_loss = np.mean(val_losses)&#10;&#10;            train_r2 = r2_score(train_targets, train_predictions)&#10;            val_r2 = r2_score(val_targets, val_predictions)&#10;&#10;            # 记录历史&#10;            self.training_history['train_loss'].append(avg_train_loss)&#10;            self.training_history['val_loss'].append(avg_val_loss)&#10;            self.training_history['train_r2'].append(train_r2)&#10;            self.training_history['val_r2'].append(val_r2)&#10;&#10;            # 学习率调度&#10;            scheduler.step(avg_val_loss)&#10;&#10;            # 保存最佳模型&#10;            if avg_val_loss &lt; best_val_loss:&#10;                best_val_loss = avg_val_loss&#10;                torch.save(self.model.state_dict(), 'best_model.pth')&#10;&#10;            # 早停检查&#10;            early_stopping(avg_val_loss)&#10;&#10;            # 打印进度&#10;            if epoch % 10 == 0 or epoch &lt; 10:&#10;                print(f&quot;Epoch {epoch:3d}/{epochs}: &quot;&#10;                      f&quot;Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, &quot;&#10;                      f&quot;Train R2: {train_r2:.4f}, Val R2: {val_r2:.4f}&quot;)&#10;&#10;            if early_stopping.early_stop:&#10;                print(f&quot;Early stopping at epoch {epoch}&quot;)&#10;                break&#10;&#10;        # 加载最佳模型&#10;        if best_val_loss &lt; float('inf'):&#10;            self.model.load_state_dict(torch.load('best_model.pth'))&#10;            print(f&quot;训练完成，最佳验证损失: {best_val_loss:.4f}&quot;)&#10;&#10;        return self.training_history&#10;&#10;    def predict(self, X):&#10;        &quot;&quot;&quot;预测&quot;&quot;&quot;&#10;        if self.model is None:&#10;            raise ValueError(&quot;模型尚未训练&quot;)&#10;&#10;        X_scaled = self.scaler.transform(X)&#10;        X_tensor = torch.FloatTensor(X_scaled).to(self.device)&#10;&#10;        self.model.eval()&#10;        with torch.no_grad():&#10;            predictions = self.model(X_tensor).cpu().numpy()&#10;&#10;        return predictions&#10;&#10;    def visualize_training(self):&#10;        &quot;&quot;&quot;可视化训练过程&quot;&quot;&quot;&#10;        if not self.training_history['train_loss']:&#10;            print(&quot;没有训练历史记录&quot;)&#10;            return&#10;&#10;        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))&#10;&#10;        epochs = range(1, len(self.training_history['train_loss']) + 1)&#10;&#10;        # 损失曲线&#10;        ax1.plot(epochs, self.training_history['train_loss'], 'b-', label='训练损失', alpha=0.8)&#10;        ax1.plot(epochs, self.training_history['val_loss'], 'r-', label='验证损失', alpha=0.8)&#10;        ax1.set_title('训练和验证损失')&#10;        ax1.set_xlabel('Epoch')&#10;        ax1.set_ylabel('Loss')&#10;        ax1.legend()&#10;        ax1.grid(True)&#10;&#10;        # R2分数&#10;        ax2.plot(epochs, self.training_history['train_r2'], 'b-', label='训练R2', alpha=0.8)&#10;        ax2.plot(epochs, self.training_history['val_r2'], 'r-', label='验证R2', alpha=0.8)&#10;        ax2.set_title('训练和验证R2分数')&#10;        ax2.set_xlabel('Epoch')&#10;        ax2.set_ylabel('R2 Score')&#10;        ax2.legend()&#10;        ax2.grid(True)&#10;&#10;        # 损失对比（对数尺度）&#10;        ax3.semilogy(epochs, self.training_history['train_loss'], 'b-', label='训练损失')&#10;        ax3.semilogy(epochs, self.training_history['val_loss'], 'r-', label='验证损失')&#10;        ax3.set_title('损失曲线（对数尺度）')&#10;        ax3.set_xlabel('Epoch')&#10;        ax3.set_ylabel('Log Loss')&#10;        ax3.legend()&#10;        ax3.grid(True)&#10;&#10;        # 损失差异&#10;        loss_diff = np.array(self.training_history['val_loss']) - np.array(self.training_history['train_loss'])&#10;        ax4.plot(epochs, loss_diff, 'g-', alpha=0.8)&#10;        ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)&#10;        ax4.set_title('过拟合监控（验证损失 - 训练损失）')&#10;        ax4.set_xlabel('Epoch')&#10;        ax4.set_ylabel('Loss Difference')&#10;        ax4.grid(True)&#10;&#10;        plt.tight_layout()&#10;        plt.savefig('neural_network_training_history.png', dpi=300, bbox_inches='tight')&#10;        plt.show()&#10;&#10;    def evaluate_model(self, X_test, y_test):&#10;        &quot;&quot;&quot;评估模型&quot;&quot;&quot;&#10;        predictions = self.predict(X_test)&#10;&#10;        mse = mean_squared_error(y_test, predictions)&#10;        rmse = np.sqrt(mse)&#10;        mae = mean_absolute_error(y_test, predictions)&#10;        r2 = r2_score(y_test, predictions)&#10;&#10;        print(f&quot;\n模型评估结果:&quot;)&#10;        print(f&quot;MSE:  {mse:.4f}&quot;)&#10;        print(f&quot;RMSE: {rmse:.4f}&quot;)&#10;        print(f&quot;MAE:  {mae:.4f}&quot;)&#10;        print(f&quot;R2:   {r2:.4f}&quot;)&#10;&#10;        # 预测vs实际值图&#10;        plt.figure(figsize=(12, 5))&#10;&#10;        plt.subplot(1, 2, 1)&#10;        plt.scatter(y_test, predictions, alpha=0.6)&#10;        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)&#10;        plt.xlabel('实际评分')&#10;        plt.ylabel('预测评分')&#10;        plt.title(f'预测vs实际评分 (R2={r2:.4f})')&#10;        plt.grid(True)&#10;&#10;        plt.subplot(1, 2, 2)&#10;        residuals = y_test - predictions&#10;        plt.scatter(predictions, residuals, alpha=0.6)&#10;        plt.axhline(y=0, color='r', linestyle='--')&#10;        plt.xlabel('预测评分')&#10;        plt.ylabel('残差')&#10;        plt.title('残差图')&#10;        plt.grid(True)&#10;&#10;        plt.tight_layout()&#10;        plt.savefig('model_evaluation.png', dpi=300, bbox_inches='tight')&#10;        plt.show()&#10;&#10;        return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}&#10;&#10;def main():&#10;    &quot;&quot;&quot;主函数&quot;&quot;&quot;&#10;    # 创建预测器&#10;    predictor = EnhancedMovieRatingPredictor()&#10;&#10;    # 加载数据&#10;    train_df, test_df = predictor.load_data()&#10;    if train_df is None:&#10;        return&#10;&#10;    print(&quot;开始特征工程...&quot;)&#10;&#10;    # 训练集特征工程&#10;    train_processed = predictor.comprehensive_feature_engineering(train_df, is_train=True)&#10;    X_train = predictor.prepare_features(train_processed, is_train=True)&#10;    y_train = train_processed['rating'].values  # 修改这里：使用正确的列名&#10;&#10;    print(f&quot;训练特征形状: {X_train.shape}&quot;)&#10;    print(f&quot;目标值统计: min={y_train.min():.2f}, max={y_train.max():.2f}, mean={y_train.mean():.2f}&quot;)&#10;&#10;    # 划分训练和测试集&#10;    X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(&#10;        X_train, y_train, test_size=0.2, random_state=42&#10;    )&#10;&#10;    # 交叉验证评估&#10;    print(&quot;\n=== 交叉验证评估 ===&quot;)&#10;    cv_score = predictor.train_with_cross_validation(&#10;        X_train_split, y_train_split, n_splits=5, epochs=100&#10;    )&#10;&#10;    # 完整训练&#10;    print(&quot;\n=== 完整模型训练 ===&quot;)&#10;    history = predictor.train(&#10;        X_train_split, y_train_split,&#10;        validation_split=0.2,&#10;        epochs=300,&#10;        batch_size=32,&#10;        learning_rate=0.001&#10;    )&#10;&#10;    # 可视化训练过程&#10;    predictor.visualize_training()&#10;&#10;    # 评估模型&#10;    print(&quot;\n=== 模型评估 ===&quot;)&#10;    evaluation = predictor.evaluate_model(X_test_split, y_test_split)&#10;&#10;    # 测试集预测&#10;    print(&quot;\n=== 测试集预测 ===&quot;)&#10;    test_processed = predictor.comprehensive_feature_engineering(test_df, is_train=False)&#10;    X_test_final = predictor.prepare_features(test_processed, is_train=False)&#10;&#10;    test_predictions = predictor.predict(X_test_final)&#10;&#10;    # 保存结果&#10;    result_df = test_df.copy()&#10;    result_df['predicted_rating'] = test_predictions&#10;    result_df.to_csv('output_result/neural_network_predictions.csv', index=False)&#10;&#10;    print(f&quot;测试集预测完成，结果保存到 neural_network_predictions.csv&quot;)&#10;    print(f&quot;预测评分范围: {test_predictions.min():.2f} - {test_predictions.max():.2f}&quot;)&#10;    print(f&quot;预测评分均值: {test_predictions.mean():.2f}&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
              <option name="updatedContent" value="import pandas as pd&#10;import numpy as np&#10;import matplotlib.pyplot as plt&#10;import seaborn as sns&#10;import torch&#10;import torch.nn as nn&#10;import torch.optim as optim&#10;from torch.utils.data import Dataset, DataLoader&#10;from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler&#10;from sklearn.model_selection import train_test_split, KFold&#10;from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error&#10;from sklearn.feature_extraction.text import TfidfVectorizer&#10;import warnings&#10;warnings.filterwarnings('ignore')&#10;&#10;# 设置中文字体&#10;plt.rcParams['font.sans-serif'] = ['SimHei']&#10;plt.rcParams['axes.unicode_minus'] = False&#10;&#10;# 设置随机种子确保可复现性&#10;torch.manual_seed(42)&#10;np.random.seed(42)&#10;if torch.cuda.is_available():&#10;    torch.cuda.manual_seed(42)&#10;&#10;class MovieDataset(Dataset):&#10;    &quot;&quot;&quot;电影数据集类&quot;&quot;&quot;&#10;    def __init__(self, features, targets=None):&#10;        self.features = torch.FloatTensor(features)&#10;        self.targets = torch.FloatTensor(targets) if targets is not None else None&#10;&#10;    def __len__(self):&#10;        return len(self.features)&#10;&#10;    def __getitem__(self, idx):&#10;        if self.targets is not None:&#10;            return self.features[idx], self.targets[idx]&#10;        return self.features[idx]&#10;&#10;class AdvancedMovieRatingNN(nn.Module):&#10;    &quot;&quot;&quot;增强的电影评分预测神经网络&quot;&quot;&quot;&#10;    def __init__(self, input_dim, hidden_dims=[1024, 512, 256, 128], dropout_rate=0.3):&#10;        super(AdvancedMovieRatingNN, self).__init__()&#10;&#10;        layers = []&#10;        prev_dim = input_dim&#10;&#10;        # 输入层归一化&#10;        layers.append(nn.BatchNorm1d(input_dim))&#10;&#10;        # 构建隐藏层&#10;        for i, hidden_dim in enumerate(hidden_dims):&#10;            layers.extend([&#10;                nn.Linear(prev_dim, hidden_dim),&#10;                nn.BatchNorm1d(hidden_dim),&#10;                nn.LeakyReLU(0.1),  # 使用LeakyReLU防止死神经元&#10;                nn.Dropout(dropout_rate * (0.8 ** i))  # 递减的dropout&#10;            ])&#10;            prev_dim = hidden_dim&#10;&#10;        # 输出层&#10;        layers.extend([&#10;            nn.Linear(prev_dim, 64),&#10;            nn.ReLU(),&#10;            nn.Dropout(0.1),&#10;            nn.Linear(64, 1),&#10;            nn.Sigmoid()  # 输出0-1，后续映射到1-10&#10;        ])&#10;&#10;        self.network = nn.Sequential(*layers)&#10;&#10;        # 权重初始化&#10;        self.apply(self._init_weights)&#10;&#10;    def _init_weights(self, m):&#10;        if isinstance(m, nn.Linear):&#10;            torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')&#10;            torch.nn.init.zeros_(m.bias)&#10;&#10;    def forward(self, x):&#10;        output = self.network(x)&#10;        # 将输出从[0,1]映射到[1,10]&#10;        return output.squeeze() * 9 + 1&#10;&#10;class EarlyStopping:&#10;    &quot;&quot;&quot;早停机制&quot;&quot;&quot;&#10;    def __init__(self, patience=15, min_delta=0.001):&#10;        self.patience = patience&#10;        self.min_delta = min_delta&#10;        self.counter = 0&#10;        self.best_loss = float('inf')&#10;        self.early_stop = False&#10;&#10;    def __call__(self, val_loss):&#10;        if val_loss &lt; self.best_loss - self.min_delta:&#10;            self.best_loss = val_loss&#10;            self.counter = 0&#10;        else:&#10;            self.counter += 1&#10;            if self.counter &gt;= self.patience:&#10;                self.early_stop = True&#10;&#10;class EnhancedMovieRatingPredictor:&#10;    def __init__(self):&#10;        self.model = None&#10;        self.scaler = StandardScaler()&#10;        self.target_scaler = MinMaxScaler(feature_range=(0, 1))  # 目标值归一化&#10;        self.label_encoders = {}&#10;        self.tfidf_vectorizers = {}&#10;        self.feature_names = []&#10;        self.training_history = {&#10;            'train_loss': [], 'val_loss': [], 'train_r2': [], 'val_r2': []&#10;        }&#10;        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')&#10;        print(f&quot;使用设备: {self.device}&quot;)&#10;&#10;    def load_data(self):&#10;        &quot;&quot;&quot;加载数据&quot;&quot;&quot;&#10;        print(&quot;正在加载数据...&quot;)&#10;&#10;        # 加载测试数据&#10;        test_df = pd.read_csv('input_data/df_movies_test.csv')&#10;        print(f&quot;测试数据形状: {test_df.shape}&quot;)&#10;&#10;        # 加载训练数据&#10;        try:&#10;            train_df = pd.read_csv('df_movies_cleaned.csv')&#10;            print(f&quot;训练数据形状: {train_df.shape}&quot;)&#10;            # 修改这里：使用正确的列名&#10;            print(f&quot;评分范围: {train_df['rating'].min():.2f} - {train_df['rating'].max():.2f}&quot;)&#10;            print(f&quot;评分分布:\n{train_df['rating'].describe()}&quot;)&#10;        except Exception as e:&#10;            print(f&quot;无法读取训练数据: {e}&quot;)&#10;            return None, None&#10;&#10;        return train_df, test_df&#10;&#10;    def comprehensive_feature_engineering(self, df, is_train=True):&#10;        &quot;&quot;&quot;综合特征工程&quot;&quot;&quot;&#10;        df = df.copy()&#10;        print(f&quot;特征工程 - 输入数据形状: {df.shape}&quot;)&#10;&#10;        # 1. 处理类型特征&#10;        if 'genres' in df.columns:&#10;            df['genres'] = df['genres'].fillna('Unknown')&#10;&#10;            # TF-IDF向量化&#10;            genres_text = df['genres'].str.replace(',', ' ')&#10;            if is_train:&#10;                self.tfidf_vectorizers['genres'] = TfidfVectorizer(&#10;                    max_features=30, stop_words=None, lowercase=True, min_df=1&#10;                )&#10;                genres_tfidf = self.tfidf_vectorizers['genres'].fit_transform(genres_text).toarray()&#10;            else:&#10;                genres_tfidf = self.tfidf_vectorizers['genres'].transform(genres_text).toarray()&#10;&#10;            # 添加TF-IDF特征&#10;            for i in range(genres_tfidf.shape[1]):&#10;                df[f'genre_tfidf_{i}'] = genres_tfidf[:, i]&#10;&#10;            # 基础特征&#10;            df['genre_count'] = df['genres'].str.count(',') + 1&#10;            df['is_action'] = df['genres'].str.contains('Action', na=False).astype(int)&#10;            df['is_drama'] = df['genres'].str.contains('Drama', na=False).astype(int)&#10;            df['is_comedy'] = df['genres'].str.contains('Comedy', na=False).astype(int)&#10;            df['is_thriller'] = df['genres'].str.contains('Thriller', na=False).astype(int)&#10;            df['is_romance'] = df['genres'].str.contains('Romance', na=False).astype(int)&#10;&#10;        # 2. 处理演员特征&#10;        if 'cast' in df.columns:&#10;            df['cast'] = df['cast'].fillna('Unknown')&#10;&#10;            # 演员TF-IDF&#10;            cast_text = df['cast'].str.replace(',', ' ')&#10;            if is_train:&#10;                self.tfidf_vectorizers['cast'] = TfidfVectorizer(&#10;                    max_features=50, stop_words=None, lowercase=True, min_df=1&#10;                )&#10;                cast_tfidf = self.tfidf_vectorizers['cast'].fit_transform(cast_text).toarray()&#10;            else:&#10;                cast_tfidf = self.tfidf_vectorizers['cast'].transform(cast_text).toarray()&#10;&#10;            for i in range(cast_tfidf.shape[1]):&#10;                df[f'cast_tfidf_{i}'] = cast_tfidf[:, i]&#10;&#10;            df['cast_count'] = df['cast'].str.count(',') + 1&#10;&#10;        # 3. 处理导演特征 - 修复Unknown标签错误&#10;        if 'director' in df.columns:&#10;            df['director'] = df['director'].fillna('Unknown')&#10;            df['has_director'] = (df['director'] != 'Unknown').astype(int)&#10;&#10;            if is_train:&#10;                # 训练时拟合编码器&#10;                unique_directors = df['director'].unique()&#10;                self.label_encoders['director'] = LabelEncoder()&#10;                self.label_encoders['director'].fit(unique_directors)&#10;                df['director_encoded'] = self.label_encoders['director'].transform(df['director'])&#10;            else:&#10;                # 测试时处理未见过的导演&#10;                known_directors = set(self.label_encoders['director'].classes_)&#10;                df['director_mapped'] = df['director'].apply(&#10;                    lambda x: x if x in known_directors else 'Unknown'&#10;                )&#10;                df['director_encoded'] = self.label_encoders['director'].transform(df['director_mapped'])&#10;&#10;        # 4. 处理编剧特征&#10;        if 'writers' in df.columns:&#10;            df['writers'] = df['writers'].fillna('Unknown')&#10;            df['writers_count'] = df['writers'].str.count(',') + 1&#10;            df['has_writers'] = (df['writers'] != 'Unknown').astype(int)&#10;&#10;        # 5. 处理制片公司特征&#10;        if 'production_companies' in df.columns:&#10;            df['production_companies'] = df['production_companies'].fillna('Unknown')&#10;            df['production_count'] = df['production_companies'].str.count(',') + 1&#10;            df['has_production'] = (df['production_companies'] != 'Unknown').astype(int)&#10;&#10;        # 6. 处理制片人特征&#10;        if 'producers' in df.columns:&#10;            df['producers'] = df['producers'].fillna('Unknown')&#10;            df['producers_count'] = df['producers'].str.count(',') + 1&#10;            df['has_producers'] = (df['producers'] != 'Unknown').astype(int)&#10;&#10;        # 7. 处理语言特征&#10;        if 'original_language' in df.columns:&#10;            df['original_language'] = df['original_language'].fillna('Unknown')&#10;&#10;            if is_train:&#10;                unique_languages = df['original_language'].unique()&#10;                self.label_encoders['language'] = LabelEncoder()&#10;                self.label_encoders['language'].fit(unique_languages)&#10;                df['language_encoded'] = self.label_encoders['language'].transform(df['original_language'])&#10;            else:&#10;                known_languages = set(self.label_encoders['language'].classes_)&#10;                df['language_mapped'] = df['original_language'].apply(&#10;                    lambda x: x if x in known_languages else 'Unknown'&#10;                )&#10;                df['language_encoded'] = self.label_encoders['language'].transform(df['language_mapped'])&#10;&#10;            # 语言特征&#10;            df['is_english'] = (df['original_language'] == 'EN').astype(int)&#10;            df['is_mandarin'] = (df['original_language'] == 'Mandarin').astype(int)&#10;&#10;        # 8. 处理时长特征&#10;        if 'runtime' in df.columns:&#10;            df['runtime'] = df['runtime'].fillna(df['runtime'].median() if is_train else 120)&#10;&#10;            # 时长分类&#10;            df['runtime_short'] = (df['runtime'] &lt;= 90).astype(int)&#10;            df['runtime_normal'] = ((df['runtime'] &gt; 90) &amp; (df['runtime'] &lt;= 150)).astype(int)&#10;            df['runtime_long'] = (df['runtime'] &gt; 150).astype(int)&#10;&#10;            # 时长变换&#10;            df['runtime_log'] = np.log1p(df['runtime'])&#10;            df['runtime_sqrt'] = np.sqrt(df['runtime'])&#10;&#10;        # 9. 交互特征&#10;        if 'cast_count' in df.columns and 'runtime' in df.columns:&#10;            df['cast_runtime_ratio'] = df['cast_count'] / (df['runtime'] + 1)&#10;            df['cast_density'] = df['cast_count'] / np.log1p(df['runtime'])&#10;&#10;        if 'writers_count' in df.columns and 'production_count' in df.columns:&#10;            df['creative_team_size'] = df['writers_count'] + df['production_count']&#10;            df['production_complexity'] = df['writers_count'] * df['production_count']&#10;&#10;        # 10. 统计特征&#10;        numeric_cols = ['genre_count', 'cast_count', 'writers_count', 'production_count', 'runtime']&#10;        for col in numeric_cols:&#10;            if col in df.columns:&#10;                df[f'{col}_normalized'] = (df[col] - df[col].min()) / (df[col].max() - df[col].min() + 1e-8)&#10;&#10;        print(f&quot;特征工程后数据形状: {df.shape}&quot;)&#10;        return df&#10;&#10;    def prepare_features(self, df, is_train=True):&#10;        &quot;&quot;&quot;准备训练特征&quot;&quot;&quot;&#10;        # 选择数值特征&#10;        feature_cols = []&#10;&#10;        # TF-IDF特征&#10;        tfidf_cols = [col for col in df.columns if 'tfidf' in col]&#10;        feature_cols.extend(tfidf_cols)&#10;&#10;        # 数值特征&#10;        numeric_features = [&#10;            'genre_count', 'cast_count', 'writers_count', 'production_count',&#10;            'runtime', 'runtime_log', 'runtime_sqrt',&#10;            'director_encoded', 'language_encoded',&#10;            'cast_runtime_ratio', 'cast_density', 'creative_team_size', 'production_complexity'&#10;        ]&#10;&#10;        # 二进制特征&#10;        binary_features = [&#10;            'has_director', 'has_writers', 'has_production', 'has_producers',&#10;            'runtime_short', 'runtime_normal', 'runtime_long',&#10;            'is_action', 'is_drama', 'is_comedy', 'is_thriller', 'is_romance',&#10;            'is_english', 'is_mandarin'&#10;        ]&#10;&#10;        # 归一化特征&#10;        normalized_features = [col for col in df.columns if col.endswith('_normalized')]&#10;&#10;        # 合并所有特征&#10;        all_features = numeric_features + binary_features + normalized_features&#10;        available_features = [col for col in all_features if col in df.columns]&#10;        feature_cols.extend(available_features)&#10;&#10;        # 去重&#10;        feature_cols = list(set(feature_cols))&#10;&#10;        if is_train:&#10;            self.feature_names = feature_cols&#10;&#10;        print(f&quot;使用 {len(feature_cols)} 个特征进行训练&quot;)&#10;&#10;        # 提取特征矩阵&#10;        X = df[feature_cols].values&#10;&#10;        # 处理无穷大和NaN&#10;        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)&#10;&#10;        return X&#10;&#10;    def train_with_cross_validation(self, X, y, n_splits=5, epochs=200, batch_size=64, learning_rate=0.001):&#10;        &quot;&quot;&quot;使用交叉验证训练模型&quot;&quot;&quot;&#10;        print(f&quot;开始交叉验证训练，数据形状: X={X.shape}, y={y.shape}&quot;)&#10;&#10;        kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)&#10;        cv_scores = []&#10;&#10;        for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):&#10;            print(f&quot;\n=== 第 {fold+1} 折交叉验证 ===&quot;)&#10;&#10;            X_train_fold, X_val_fold = X[train_idx], X[val_idx]&#10;            y_train_fold, y_val_fold = y[train_idx], y[val_idx]&#10;&#10;            # 标准化特征&#10;            fold_scaler = StandardScaler()&#10;            X_train_scaled = fold_scaler.fit_transform(X_train_fold)&#10;            X_val_scaled = fold_scaler.transform(X_val_fold)&#10;&#10;            # 创建数据加载器&#10;            train_dataset = MovieDataset(X_train_scaled, y_train_fold)&#10;            val_dataset = MovieDataset(X_val_scaled, y_val_fold)&#10;&#10;            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)&#10;            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)&#10;&#10;            # 创建模型&#10;            model = AdvancedMovieRatingNN(X.shape[1]).to(self.device)&#10;            optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)&#10;            scheduler = optim.lr_scheduler.ReduceLROnPlateau(&#10;                optimizer, mode='min', factor=0.8, patience=10&#10;            )&#10;            criterion = nn.MSELoss()&#10;&#10;            # 训练模型&#10;            best_val_loss = float('inf')&#10;            for epoch in range(epochs):&#10;                # 训练阶段&#10;                model.train()&#10;                train_losses = []&#10;                for batch_X, batch_y in train_loader:&#10;                    batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)&#10;&#10;                    optimizer.zero_grad()&#10;                    outputs = model(batch_X)&#10;                    loss = criterion(outputs, batch_y)&#10;                    loss.backward()&#10;                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)&#10;                    optimizer.step()&#10;&#10;                    train_losses.append(loss.item())&#10;&#10;                # 验证阶段&#10;                model.eval()&#10;                val_losses = []&#10;                with torch.no_grad():&#10;                    for batch_X, batch_y in val_loader:&#10;                        batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)&#10;                        outputs = model(batch_X)&#10;                        loss = criterion(outputs, batch_y)&#10;                        val_losses.append(loss.item())&#10;&#10;                avg_train_loss = np.mean(train_losses)&#10;                avg_val_loss = np.mean(val_losses)&#10;                scheduler.step(avg_val_loss)&#10;&#10;                if avg_val_loss &lt; best_val_loss:&#10;                    best_val_loss = avg_val_loss&#10;&#10;                if epoch % 20 == 0:&#10;                    print(f&quot;Epoch {epoch:3d}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}&quot;)&#10;&#10;            # 计算最终验证分数&#10;            model.eval()&#10;            with torch.no_grad():&#10;                val_predictions = []&#10;                for batch_X, _ in val_loader:&#10;                    batch_X = batch_X.to(self.device)&#10;                    outputs = model(batch_X)&#10;                    val_predictions.extend(outputs.cpu().numpy())&#10;&#10;            val_r2 = r2_score(y_val_fold, val_predictions)&#10;            cv_scores.append(val_r2)&#10;            print(f&quot;第 {fold+1} 折 R2 分数: {val_r2:.4f}&quot;)&#10;&#10;        print(f&quot;\n交叉验证平均 R2 分数: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}&quot;)&#10;        return np.mean(cv_scores)&#10;&#10;    def train(self, X, y, validation_split=0.2, epochs=300, batch_size=64, learning_rate=0.001):&#10;        &quot;&quot;&quot;训练模型&quot;&quot;&quot;&#10;        print(f&quot;开始训练，数据形状: X={X.shape}, y={y.shape}&quot;)&#10;        print(f&quot;目标值范围: {y.min():.2f} - {y.max():.2f}&quot;)&#10;&#10;        # 划分训练集和验证集&#10;        X_train, X_val, y_train, y_val = train_test_split(&#10;            X, y, test_size=validation_split, random_state=42, stratify=None&#10;        )&#10;&#10;        # 标准化特征&#10;        X_train_scaled = self.scaler.fit_transform(X_train)&#10;        X_val_scaled = self.scaler.transform(X_val)&#10;&#10;        print(f&quot;训练集大小: {X_train_scaled.shape[0]}, 验证集大小: {X_val_scaled.shape[0]}&quot;)&#10;&#10;        # 创建数据加载器&#10;        train_dataset = MovieDataset(X_train_scaled, y_train)&#10;        val_dataset = MovieDataset(X_val_scaled, y_val)&#10;&#10;        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)&#10;        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)&#10;&#10;        # 创建模型&#10;        self.model = AdvancedMovieRatingNN(X.shape[1]).to(self.device)&#10;&#10;        # 优化器和调度器&#10;        optimizer = optim.AdamW(&#10;            self.model.parameters(),&#10;            lr=learning_rate,&#10;            weight_decay=0.01,&#10;            betas=(0.9, 0.999)&#10;        )&#10;&#10;        scheduler = optim.lr_scheduler.ReduceLROnPlateau(&#10;            optimizer, mode='min', factor=0.8, patience=15, min_lr=1e-6&#10;        )&#10;&#10;        criterion = nn.MSELoss()&#10;        early_stopping = EarlyStopping(patience=25, min_delta=0.001)&#10;&#10;        print(&quot;开始训练...&quot;)&#10;        best_val_loss = float('inf')&#10;&#10;        for epoch in range(epochs):&#10;            # 训练阶段&#10;            self.model.train()&#10;            train_losses = []&#10;            train_predictions = []&#10;            train_targets = []&#10;&#10;            for batch_X, batch_y in train_loader:&#10;                batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)&#10;&#10;                optimizer.zero_grad()&#10;                outputs = self.model(batch_X)&#10;                loss = criterion(outputs, batch_y)&#10;                loss.backward()&#10;&#10;                # 梯度裁剪&#10;                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)&#10;                optimizer.step()&#10;&#10;                train_losses.append(loss.item())&#10;                train_predictions.extend(outputs.cpu().detach().numpy())&#10;                train_targets.extend(batch_y.cpu().numpy())&#10;&#10;            # 验证阶段&#10;            self.model.eval()&#10;            val_losses = []&#10;            val_predictions = []&#10;            val_targets = []&#10;&#10;            with torch.no_grad():&#10;                for batch_X, batch_y in val_loader:&#10;                    batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)&#10;                    outputs = self.model(batch_X)&#10;                    loss = criterion(outputs, batch_y)&#10;&#10;                    val_losses.append(loss.item())&#10;                    val_predictions.extend(outputs.cpu().numpy())&#10;                    val_targets.extend(batch_y.cpu().numpy())&#10;&#10;            # 计算指标&#10;            avg_train_loss = np.mean(train_losses)&#10;            avg_val_loss = np.mean(val_losses)&#10;&#10;            train_r2 = r2_score(train_targets, train_predictions)&#10;            val_r2 = r2_score(val_targets, val_predictions)&#10;&#10;            # 记录历史&#10;            self.training_history['train_loss'].append(avg_train_loss)&#10;            self.training_history['val_loss'].append(avg_val_loss)&#10;            self.training_history['train_r2'].append(train_r2)&#10;            self.training_history['val_r2'].append(val_r2)&#10;&#10;            # 学习率调度&#10;            scheduler.step(avg_val_loss)&#10;&#10;            # 保存最佳模型&#10;            if avg_val_loss &lt; best_val_loss:&#10;                best_val_loss = avg_val_loss&#10;                torch.save(self.model.state_dict(), 'best_model.pth')&#10;&#10;            # 早停检查&#10;            early_stopping(avg_val_loss)&#10;&#10;            # 打印进度&#10;            if epoch % 10 == 0 or epoch &lt; 10:&#10;                print(f&quot;Epoch {epoch:3d}/{epochs}: &quot;&#10;                      f&quot;Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, &quot;&#10;                      f&quot;Train R2: {train_r2:.4f}, Val R2: {val_r2:.4f}&quot;)&#10;&#10;            if early_stopping.early_stop:&#10;                print(f&quot;Early stopping at epoch {epoch}&quot;)&#10;                break&#10;&#10;        # 加载最佳模型&#10;        if best_val_loss &lt; float('inf'):&#10;            self.model.load_state_dict(torch.load('best_model.pth'))&#10;            print(f&quot;训练完成，最佳验证损失: {best_val_loss:.4f}&quot;)&#10;&#10;        return self.training_history&#10;&#10;    def predict(self, X):&#10;        &quot;&quot;&quot;预测&quot;&quot;&quot;&#10;        if self.model is None:&#10;            raise ValueError(&quot;模型尚未训练&quot;)&#10;&#10;        X_scaled = self.scaler.transform(X)&#10;        X_tensor = torch.FloatTensor(X_scaled).to(self.device)&#10;&#10;        self.model.eval()&#10;        with torch.no_grad():&#10;            predictions = self.model(X_tensor).cpu().numpy()&#10;&#10;        return predictions&#10;&#10;    def visualize_training(self):&#10;        &quot;&quot;&quot;可视化训练过程&quot;&quot;&quot;&#10;        if not self.training_history['train_loss']:&#10;            print(&quot;没有训练历史记录&quot;)&#10;            return&#10;&#10;        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))&#10;&#10;        epochs = range(1, len(self.training_history['train_loss']) + 1)&#10;&#10;        # 损失曲线&#10;        ax1.plot(epochs, self.training_history['train_loss'], 'b-', label='训练损失', alpha=0.8)&#10;        ax1.plot(epochs, self.training_history['val_loss'], 'r-', label='验证损失', alpha=0.8)&#10;        ax1.set_title('训练和验证损失')&#10;        ax1.set_xlabel('Epoch')&#10;        ax1.set_ylabel('Loss')&#10;        ax1.legend()&#10;        ax1.grid(True)&#10;&#10;        # R2分数&#10;        ax2.plot(epochs, self.training_history['train_r2'], 'b-', label='训练R2', alpha=0.8)&#10;        ax2.plot(epochs, self.training_history['val_r2'], 'r-', label='验证R2', alpha=0.8)&#10;        ax2.set_title('训练和验证R2分数')&#10;        ax2.set_xlabel('Epoch')&#10;        ax2.set_ylabel('R2 Score')&#10;        ax2.legend()&#10;        ax2.grid(True)&#10;&#10;        # 损失对比（对数尺度）&#10;        ax3.semilogy(epochs, self.training_history['train_loss'], 'b-', label='训练损失')&#10;        ax3.semilogy(epochs, self.training_history['val_loss'], 'r-', label='验证损失')&#10;        ax3.set_title('损失曲线（对数尺度）')&#10;        ax3.set_xlabel('Epoch')&#10;        ax3.set_ylabel('Log Loss')&#10;        ax3.legend()&#10;        ax3.grid(True)&#10;&#10;        # 损失差异&#10;        loss_diff = np.array(self.training_history['val_loss']) - np.array(self.training_history['train_loss'])&#10;        ax4.plot(epochs, loss_diff, 'g-', alpha=0.8)&#10;        ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)&#10;        ax4.set_title('过拟合监控（验证损失 - 训练损失）')&#10;        ax4.set_xlabel('Epoch')&#10;        ax4.set_ylabel('Loss Difference')&#10;        ax4.grid(True)&#10;&#10;        plt.tight_layout()&#10;        plt.savefig('neural_network_training_history.png', dpi=300, bbox_inches='tight')&#10;        plt.show()&#10;&#10;    def evaluate_model(self, X_test, y_test):&#10;        &quot;&quot;&quot;评估模型&quot;&quot;&quot;&#10;        predictions = self.predict(X_test)&#10;&#10;        mse = mean_squared_error(y_test, predictions)&#10;        rmse = np.sqrt(mse)&#10;        mae = mean_absolute_error(y_test, predictions)&#10;        r2 = r2_score(y_test, predictions)&#10;&#10;        print(f&quot;\n模型评估结果:&quot;)&#10;        print(f&quot;MSE:  {mse:.4f}&quot;)&#10;        print(f&quot;RMSE: {rmse:.4f}&quot;)&#10;        print(f&quot;MAE:  {mae:.4f}&quot;)&#10;        print(f&quot;R2:   {r2:.4f}&quot;)&#10;&#10;        # 预测vs实际值图&#10;        plt.figure(figsize=(12, 5))&#10;&#10;        plt.subplot(1, 2, 1)&#10;        plt.scatter(y_test, predictions, alpha=0.6)&#10;        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)&#10;        plt.xlabel('实际评分')&#10;        plt.ylabel('预测评分')&#10;        plt.title(f'预测vs实际评分 (R2={r2:.4f})')&#10;        plt.grid(True)&#10;&#10;        plt.subplot(1, 2, 2)&#10;        residuals = y_test - predictions&#10;        plt.scatter(predictions, residuals, alpha=0.6)&#10;        plt.axhline(y=0, color='r', linestyle='--')&#10;        plt.xlabel('预测评分')&#10;        plt.ylabel('残差')&#10;        plt.title('残差图')&#10;        plt.grid(True)&#10;&#10;        plt.tight_layout()&#10;        plt.savefig('model_evaluation.png', dpi=300, bbox_inches='tight')&#10;        plt.show()&#10;&#10;        return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}&#10;&#10;def main():&#10;    &quot;&quot;&quot;主函数&quot;&quot;&quot;&#10;    # 创建预测器&#10;    predictor = EnhancedMovieRatingPredictor()&#10;&#10;    # 加载数据&#10;    train_df, test_df = predictor.load_data()&#10;    if train_df is None:&#10;        return&#10;&#10;    print(&quot;开始特征工程...&quot;)&#10;&#10;    # 训练集特征工程&#10;    train_processed = predictor.comprehensive_feature_engineering(train_df, is_train=True)&#10;    X_train = predictor.prepare_features(train_processed, is_train=True)&#10;    y_train = train_processed['rating'].values  # 修改这里：使用正确的列名&#10;&#10;    print(f&quot;训练特征形状: {X_train.shape}&quot;)&#10;    print(f&quot;目标值统计: min={y_train.min():.2f}, max={y_train.max():.2f}, mean={y_train.mean():.2f}&quot;)&#10;&#10;    # 划分训练和测试集&#10;    X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(&#10;        X_train, y_train, test_size=0.2, random_state=42&#10;    )&#10;&#10;    # 交叉验证评估&#10;    print(&quot;\n=== 交叉验证评估 ===&quot;)&#10;    cv_score = predictor.train_with_cross_validation(&#10;        X_train_split, y_train_split, n_splits=5, epochs=100&#10;    )&#10;&#10;    # 完整训练&#10;    print(&quot;\n=== 完整模型训练 ===&quot;)&#10;    history = predictor.train(&#10;        X_train_split, y_train_split,&#10;        validation_split=0.2,&#10;        epochs=300,&#10;        batch_size=32,&#10;        learning_rate=0.001&#10;    )&#10;&#10;    # 可视化训练过程&#10;    predictor.visualize_training()&#10;&#10;    # 评估模型&#10;    print(&quot;\n=== 模型评估 ===&quot;)&#10;    evaluation = predictor.evaluate_model(X_test_split, y_test_split)&#10;&#10;    # 测试集预测&#10;    print(&quot;\n=== 测试集预测 ===&quot;)&#10;    test_processed = predictor.comprehensive_feature_engineering(test_df, is_train=False)&#10;    X_test_final = predictor.prepare_features(test_processed, is_train=False)&#10;&#10;    test_predictions = predictor.predict(X_test_final)&#10;&#10;    # 保存结果&#10;    result_df = test_df.copy()&#10;    result_df['predicted_rating'] = test_predictions&#10;    result_df.to_csv('output_result/neural_network_predictions.csv', index=False)&#10;&#10;    print(f&quot;测试集预测完成，结果保存到 neural_network_predictions.csv&quot;)&#10;    print(f&quot;预测评分范围: {test_predictions.min():.2f} - {test_predictions.max():.2f}&quot;)&#10;    print(f&quot;预测评分均值: {test_predictions.mean():.2f}&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/movie_predictor.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/movie_predictor.py" />
              <option name="originalContent" value="import pandas as pd&#10;import numpy as np&#10;import matplotlib.pyplot as plt&#10;from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor&#10;from sklearn.linear_model import Ridge&#10;from sklearn.model_selection import train_test_split&#10;from sklearn.preprocessing import OneHotEncoder, StandardScaler&#10;from sklearn.compose import ColumnTransformer&#10;from sklearn.pipeline import Pipeline&#10;from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error&#10;import warnings&#10;warnings.filterwarnings('ignore')&#10;&#10;def load_data():&#10;    &quot;&quot;&quot;加载数据&quot;&quot;&quot;&#10;    print(&quot;正在加载数据...&quot;)&#10;&#10;    # 加载测试数据&#10;    test_df = pd.read_csv('input_data/df_movies_test.csv')&#10;    print(f&quot;测试数据形状: {test_df.shape}&quot;)&#10;&#10;    # 尝试加载训练数据&#10;    try:&#10;        train_df = pd.read_csv('df_movies_cleaned.csv')&#10;        print(f&quot;训练数据形状: {train_df.shape}&quot;)&#10;    except Exception as e:&#10;        print(f&quot;无法直接读取训练数据: {e}&quot;)&#10;        # 创建模拟训练数据用于演示&#10;        print(&quot;创建基于测试数据结构的模拟训练数据...&quot;)&#10;        train_df = test_df.copy()&#10;        # 添加模拟评分&#10;        np.random.seed(42)&#10;        train_df['rating'] = np.random.normal(7.0, 1.5, len(train_df))&#10;        train_df['rating'] = np.clip(train_df['rating'], 1, 10)&#10;&#10;        # 扩展训练数据&#10;        train_df = pd.concat([train_df] * 100, ignore_index=True)&#10;        train_df['rating'] = np.random.normal(7.0, 1.5, len(train_df))&#10;        train_df['rating'] = np.clip(train_df['rating'], 1, 10)&#10;        print(f&quot;模拟训练数据形状: {train_df.shape}&quot;)&#10;&#10;    return train_df, test_df&#10;&#10;def feature_engineering(df):&#10;    &quot;&quot;&quot;特征工程&quot;&quot;&quot;&#10;    df = df.copy()&#10;&#10;    # 处理类型特征&#10;    if 'genres' in df.columns:&#10;        df['main_genre'] = df['genres'].str.split(',').str[0]&#10;        df['genre_count'] = df['genres'].str.count(',') + 1&#10;        df['genre_count'] = df['genre_count'].fillna(1)&#10;&#10;    # 处理演员特征&#10;    if 'cast' in df.columns:&#10;        df['cast_count'] = df['cast'].str.count(',') + 1&#10;        df['cast_count'] = df['cast_count'].fillna(0)&#10;&#10;    # 处理导演特征&#10;    if 'director' in df.columns:&#10;        df['has_director'] = df['director'].notna().astype(int)&#10;&#10;    # 处理编剧特征&#10;    if 'writers' in df.columns:&#10;        df['writers_count'] = df['writers'].str.count(',') + 1&#10;        df['writers_count'] = df['writers_count'].fillna(0)&#10;&#10;    # 处理制片公司特征&#10;    if 'production_companies' in df.columns:&#10;        df['production_count'] = df['production_companies'].str.count(',') + 1&#10;        df['production_count'] = df['production_count'].fillna(0)&#10;&#10;    # 处理语言特征&#10;    if 'original_language' in df.columns:&#10;        df['lang'] = df['original_language'].fillna('Unknown')&#10;&#10;    # 处理时长特征&#10;    if 'runtime' in df.columns:&#10;        df['runtime'] = df['runtime'].fillna(df['runtime'].median())&#10;&#10;    return df&#10;&#10;def prepare_features(df):&#10;    &quot;&quot;&quot;准备特征&quot;&quot;&quot;&#10;    features = {}&#10;&#10;    # 数值特征&#10;    if 'runtime' in df.columns:&#10;        features['runtime'] = df['runtime'].fillna(120)&#10;    if 'cast_count' in df.columns:&#10;        features['cast_count'] = df['cast_count'].fillna(0)&#10;    if 'writers_count' in df.columns:&#10;        features['writers_count'] = df['writers_count'].fillna(0)&#10;    if 'production_count' in df.columns:&#10;        features['production_count'] = df['production_count'].fillna(0)&#10;    if 'genre_count' in df.columns:&#10;        features['genre_count'] = df['genre_count'].fillna(1)&#10;    if 'has_director' in df.columns:&#10;        features['has_director'] = df['has_director'].fillna(0)&#10;&#10;    # 类别特征&#10;    if 'main_genre' in df.columns:&#10;        features['main_genre'] = df['main_genre'].fillna('Unknown')&#10;    if 'lang' in df.columns:&#10;        features['lang'] = df['lang'].fillna('Unknown')&#10;&#10;    features_df = pd.DataFrame(features)&#10;&#10;    # 定义特征类型&#10;    numeric_features = [col for col in features_df.columns if col not in ['main_genre', 'lang']]&#10;    categorical_features = [col for col in features_df.columns if col in ['main_genre', 'lang']]&#10;&#10;    return features_df, numeric_features, categorical_features&#10;&#10;def train_models(X_train, y_train):&#10;    &quot;&quot;&quot;训练模型&quot;&quot;&quot;&#10;    print(&quot;开始训练模型...&quot;)&#10;&#10;    # 准备特征&#10;    X_features, numeric_features, categorical_features = prepare_features(X_train)&#10;&#10;    # 创建预处理器&#10;    preprocessor = ColumnTransformer(&#10;        transformers=[&#10;            ('num', StandardScaler(), numeric_features),&#10;            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)&#10;        ]&#10;    )&#10;&#10;    # 定义模型&#10;    models = {&#10;        'Random Forest': RandomForestRegressor(&#10;            n_estimators=100,&#10;            max_depth=10,&#10;            random_state=42,&#10;            n_jobs=-1&#10;        ),&#10;        'Gradient Boosting': GradientBoostingRegressor(&#10;            n_estimators=100,&#10;            learning_rate=0.1,&#10;            max_depth=5,&#10;            random_state=42&#10;        ),&#10;        'Ridge Regression': Ridge(alpha=1.0)&#10;    }&#10;&#10;    # 训练和评估&#10;    results = {}&#10;    trained_models = {}&#10;&#10;    # 分割验证集&#10;    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(&#10;        X_features, y_train, test_size=0.2, random_state=42&#10;    )&#10;&#10;    for name, model in models.items():&#10;        print(f&quot;训练 {name}...&quot;)&#10;&#10;        # 创建管道&#10;        pipeline = Pipeline([&#10;            ('preprocessor', preprocessor),&#10;            ('model', model)&#10;        ])&#10;&#10;        # 训练&#10;        pipeline.fit(X_train_split, y_train_split)&#10;&#10;        # 预测&#10;        y_pred = pipeline.predict(X_val_split)&#10;&#10;        # 评估&#10;        mse = mean_squared_error(y_val_split, y_pred)&#10;        rmse = np.sqrt(mse)&#10;        mae = mean_absolute_error(y_val_split, y_pred)&#10;        r2 = r2_score(y_val_split, y_pred)&#10;&#10;        results[name] = {&#10;            'MSE': mse,&#10;            'RMSE': rmse,&#10;            'MAE': mae,&#10;            'R2': r2,&#10;            'predictions': y_pred&#10;        }&#10;&#10;        trained_models[name] = pipeline&#10;&#10;        print(f&quot;{name} - RMSE: {rmse:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}&quot;)&#10;&#10;    # 选择最佳模型&#10;    best_model_name = min(results.keys(), key=lambda x: results[x]['RMSE'])&#10;    best_model = trained_models[best_model_name]&#10;&#10;    print(f&quot;\n最佳模型: {best_model_name}&quot;)&#10;&#10;    return results, trained_models, best_model, X_val_split, y_val_split&#10;&#10;def visualize_results(results, best_model, X_val, y_val):&#10;    &quot;&quot;&quot;可视化结果&quot;&quot;&quot;&#10;    print(&quot;生成可视化结果...&quot;)&#10;&#10;    plt.figure(figsize=(15, 10))&#10;&#10;    # 1. 模型性能比较 - RMSE&#10;    plt.subplot(2, 3, 1)&#10;    models = list(results.keys())&#10;    rmse_values = [results[m]['RMSE'] for m in models]&#10;    plt.bar(models, rmse_values, color='skyblue', alpha=0.7)&#10;    plt.title('模型RMSE比较')&#10;    plt.ylabel('RMSE')&#10;    plt.xticks(rotation=45)&#10;    for i, v in enumerate(rmse_values):&#10;        plt.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')&#10;&#10;    # 2. 模型性能比较 - R²&#10;    plt.subplot(2, 3, 2)&#10;    r2_values = [results[m]['R2'] for m in models]&#10;    plt.bar(models, r2_values, color='lightgreen', alpha=0.7)&#10;    plt.title('模型R²比较')&#10;    plt.ylabel('R²')&#10;    plt.xticks(rotation=45)&#10;    for i, v in enumerate(r2_values):&#10;        plt.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')&#10;&#10;    # 3. 预测vs实际&#10;    plt.subplot(2, 3, 3)&#10;    X_features, _, _ = prepare_features(X_val)&#10;    y_pred = best_model.predict(X_features)&#10;    plt.scatter(y_val, y_pred, alpha=0.6, color='blue')&#10;    plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)&#10;    plt.xlabel('实际评分')&#10;    plt.ylabel('预测评分')&#10;    plt.title('预测值 vs 实际值')&#10;&#10;    # 4. 残差图&#10;    plt.subplot(2, 3, 4)&#10;    residuals = y_val - y_pred&#10;    plt.scatter(y_pred, residuals, alpha=0.6, color='green')&#10;    plt.axhline(y=0, color='r', linestyle='--')&#10;    plt.xlabel('预测评分')&#10;    plt.ylabel('残差')&#10;    plt.title('残差图')&#10;&#10;    # 5. 损失对比&#10;    plt.subplot(2, 3, 5)&#10;    mae_values = [results[m]['MAE'] for m in models]&#10;    plt.bar(models, mae_values, color='orange', alpha=0.7)&#10;    plt.title('模型MAE比较')&#10;    plt.ylabel('MAE')&#10;    plt.xticks(rotation=45)&#10;    for i, v in enumerate(mae_values):&#10;        plt.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')&#10;&#10;    # 6. 特征重要性&#10;    plt.subplot(2, 3, 6)&#10;    if hasattr(best_model.named_steps['model'], 'feature_importances_'):&#10;        importances = best_model.named_steps['model'].feature_importances_&#10;        feature_names = best_model.named_steps['preprocessor'].get_feature_names_out()&#10;&#10;        # 选择前10个重要特征&#10;        indices = np.argsort(importances)[::-1][:10]&#10;        plt.barh(range(10), importances[indices])&#10;        plt.title('特征重要性 (Top 10)')&#10;        plt.yticks(range(10), [feature_names[i] for i in indices])&#10;    else:&#10;        plt.text(0.5, 0.5, '该模型无特征重要性', ha='center', va='center',&#10;                transform=plt.gca().transAxes)&#10;        plt.title('特征重要性')&#10;&#10;    plt.tight_layout()&#10;    plt.savefig('model_evaluation.png', dpi=300, bbox_inches='tight')&#10;    plt.show()&#10;&#10;def predict_test_data(best_model, test_df):&#10;    &quot;&quot;&quot;预测测试数据&quot;&quot;&quot;&#10;    print(&quot;对测试数据进行预测...&quot;)&#10;&#10;    # 特征工程&#10;    test_df_processed = feature_engineering(test_df)&#10;    X_test_features, _, _ = prepare_features(test_df_processed)&#10;&#10;    # 预测&#10;    predictions = best_model.predict(X_test_features)&#10;&#10;    # 确保预测值在合理范围内&#10;    predictions = np.clip(predictions, 1, 10)&#10;&#10;    return predictions&#10;&#10;def main():&#10;    &quot;&quot;&quot;主函数&quot;&quot;&quot;&#10;    # 加载数据&#10;    train_df, test_df = load_data()&#10;&#10;    # 特征工程&#10;    train_df = feature_engineering(train_df)&#10;&#10;    # 准备训练数据&#10;    if 'rating' in train_df.columns:&#10;        X_train = train_df.drop('rating', axis=1)&#10;        y_train = train_df['rating']&#10;    else:&#10;        print(&quot;训练数据中没有rating列&quot;)&#10;        return&#10;&#10;    # 训练模型&#10;    results, trained_models, best_model, X_val, y_val = train_models(X_train, y_train)&#10;&#10;    # 可视化结果&#10;    visualize_results(results, best_model, X_val, y_val)&#10;&#10;    # 预测测试数据&#10;    predictions = predict_test_data(best_model, test_df)&#10;&#10;    # 保存结果&#10;    output_df = pd.DataFrame({&#10;        'id': test_df['id'] if 'id' in test_df.columns else range(len(test_df)),&#10;        'predicted_rating': predictions&#10;    })&#10;&#10;    output_df.to_csv('output_result/predicted_ratings.csv', index=False)&#10;&#10;    print(f&quot;\n预测完成！结果已保存到 output_result/predicted_ratings.csv&quot;)&#10;    print(f&quot;预测评分范围: {predictions.min():.2f} - {predictions.max():.2f}&quot;)&#10;    print(f&quot;预测评分均值: {predictions.mean():.2f}&quot;)&#10;    print(f&quot;预测评分标准差: {predictions.std():.2f}&quot;)&#10;&#10;    # 显示模型性能总结&#10;    print(&quot;\n=== 模型性能总结 ===&quot;)&#10;    for model_name, scores in results.items():&#10;        print(f&quot;{model_name}:&quot;)&#10;        print(f&quot;  RMSE: {scores['RMSE']:.4f}&quot;)&#10;        print(f&quot;  R²:   {scores['R2']:.4f}&quot;)&#10;        print(f&quot;  MAE:  {scores['MAE']:.4f}&quot;)&#10;        print()&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
              <option name="updatedContent" value="import pandas as pd&#10;import numpy as np&#10;import matplotlib.pyplot as plt&#10;from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor&#10;from sklearn.linear_model import Ridge&#10;from sklearn.model_selection import train_test_split&#10;from sklearn.preprocessing import OneHotEncoder, StandardScaler&#10;from sklearn.compose import ColumnTransformer&#10;from sklearn.pipeline import Pipeline&#10;from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error&#10;import warnings&#10;warnings.filterwarnings('ignore')&#10;&#10;def load_data():&#10;    &quot;&quot;&quot;加载数据&quot;&quot;&quot;&#10;    print(&quot;正在加载数据...&quot;)&#10;&#10;    # 加载测试数据&#10;    test_df = pd.read_csv('input_data/df_movies_test.csv')&#10;    print(f&quot;测试数据形状: {test_df.shape}&quot;)&#10;&#10;    # 尝试加载训练数据&#10;    try:&#10;        train_df = pd.read_csv('df_movies_cleaned.csv')&#10;        print(f&quot;训练数据形状: {train_df.shape}&quot;)&#10;    except Exception as e:&#10;        print(f&quot;无法直接读取训练数据: {e}&quot;)&#10;        # 创建模拟训练数据用于演示&#10;        print(&quot;创建基于测试数据结构的模拟训练数据...&quot;)&#10;        train_df = test_df.copy()&#10;        # 添加模拟评分&#10;        np.random.seed(42)&#10;        train_df['rating'] = np.random.normal(7.0, 1.5, len(train_df))&#10;        train_df['rating'] = np.clip(train_df['rating'], 1, 10)&#10;&#10;        # 扩展训练数据&#10;        train_df = pd.concat([train_df] * 100, ignore_index=True)&#10;        train_df['rating'] = np.random.normal(7.0, 1.5, len(train_df))&#10;        train_df['rating'] = np.clip(train_df['rating'], 1, 10)&#10;        print(f&quot;模拟训练数据形状: {train_df.shape}&quot;)&#10;&#10;    return train_df, test_df&#10;&#10;def feature_engineering(df):&#10;    &quot;&quot;&quot;特征工程&quot;&quot;&quot;&#10;    df = df.copy()&#10;&#10;    # 处理类型特征&#10;    if 'genres' in df.columns:&#10;        df['main_genre'] = df['genres'].str.split(',').str[0]&#10;        df['genre_count'] = df['genres'].str.count(',') + 1&#10;        df['genre_count'] = df['genre_count'].fillna(1)&#10;&#10;    # 处理演员特征&#10;    if 'cast' in df.columns:&#10;        df['cast_count'] = df['cast'].str.count(',') + 1&#10;        df['cast_count'] = df['cast_count'].fillna(0)&#10;&#10;    # 处理导演特征&#10;    if 'director' in df.columns:&#10;        df['has_director'] = df['director'].notna().astype(int)&#10;&#10;    # 处理编剧特征&#10;    if 'writers' in df.columns:&#10;        df['writers_count'] = df['writers'].str.count(',') + 1&#10;        df['writers_count'] = df['writers_count'].fillna(0)&#10;&#10;    # 处理制片公司特征&#10;    if 'production_companies' in df.columns:&#10;        df['production_count'] = df['production_companies'].str.count(',') + 1&#10;        df['production_count'] = df['production_count'].fillna(0)&#10;&#10;    # 处理语言特征&#10;    if 'original_language' in df.columns:&#10;        df['lang'] = df['original_language'].fillna('Unknown')&#10;&#10;    # 处理时长特征&#10;    if 'runtime' in df.columns:&#10;        df['runtime'] = df['runtime'].fillna(df['runtime'].median())&#10;&#10;    return df&#10;&#10;def prepare_features(df):&#10;    &quot;&quot;&quot;准备特征&quot;&quot;&quot;&#10;    features = {}&#10;&#10;    # 数值特征&#10;    if 'runtime' in df.columns:&#10;        features['runtime'] = df['runtime'].fillna(120)&#10;    if 'cast_count' in df.columns:&#10;        features['cast_count'] = df['cast_count'].fillna(0)&#10;    if 'writers_count' in df.columns:&#10;        features['writers_count'] = df['writers_count'].fillna(0)&#10;    if 'production_count' in df.columns:&#10;        features['production_count'] = df['production_count'].fillna(0)&#10;    if 'genre_count' in df.columns:&#10;        features['genre_count'] = df['genre_count'].fillna(1)&#10;    if 'has_director' in df.columns:&#10;        features['has_director'] = df['has_director'].fillna(0)&#10;&#10;    # 类别特征&#10;    if 'main_genre' in df.columns:&#10;        features['main_genre'] = df['main_genre'].fillna('Unknown')&#10;    if 'lang' in df.columns:&#10;        features['lang'] = df['lang'].fillna('Unknown')&#10;&#10;    features_df = pd.DataFrame(features)&#10;&#10;    # 定义特征类型&#10;    numeric_features = [col for col in features_df.columns if col not in ['main_genre', 'lang']]&#10;    categorical_features = [col for col in features_df.columns if col in ['main_genre', 'lang']]&#10;&#10;    return features_df, numeric_features, categorical_features&#10;&#10;def train_models(X_train, y_train):&#10;    &quot;&quot;&quot;训练模型&quot;&quot;&quot;&#10;    print(&quot;开始训练模型...&quot;)&#10;&#10;    # 准备特征&#10;    X_features, numeric_features, categorical_features = prepare_features(X_train)&#10;&#10;    # 创建预处理器&#10;    preprocessor = ColumnTransformer(&#10;        transformers=[&#10;            ('num', StandardScaler(), numeric_features),&#10;            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)&#10;        ]&#10;    )&#10;&#10;    # 定义模型&#10;    models = {&#10;        'Random Forest': RandomForestRegressor(&#10;            n_estimators=100,&#10;            max_depth=10,&#10;            random_state=42,&#10;            n_jobs=-1&#10;        ),&#10;        'Gradient Boosting': GradientBoostingRegressor(&#10;            n_estimators=100,&#10;            learning_rate=0.1,&#10;            max_depth=5,&#10;            random_state=42&#10;        ),&#10;        'Ridge Regression': Ridge(alpha=1.0)&#10;    }&#10;&#10;    # 训练和评估&#10;    results = {}&#10;    trained_models = {}&#10;&#10;    # 分割验证集&#10;    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(&#10;        X_features, y_train, test_size=0.2, random_state=42&#10;    )&#10;&#10;    for name, model in models.items():&#10;        print(f&quot;训练 {name}...&quot;)&#10;&#10;        # 创建管道&#10;        pipeline = Pipeline([&#10;            ('preprocessor', preprocessor),&#10;            ('model', model)&#10;        ])&#10;&#10;        # 训练&#10;        pipeline.fit(X_train_split, y_train_split)&#10;&#10;        # 预测&#10;        y_pred = pipeline.predict(X_val_split)&#10;&#10;        # 评估&#10;        mse = mean_squared_error(y_val_split, y_pred)&#10;        rmse = np.sqrt(mse)&#10;        mae = mean_absolute_error(y_val_split, y_pred)&#10;        r2 = r2_score(y_val_split, y_pred)&#10;&#10;        results[name] = {&#10;            'MSE': mse,&#10;            'RMSE': rmse,&#10;            'MAE': mae,&#10;            'R2': r2,&#10;            'predictions': y_pred&#10;        }&#10;&#10;        trained_models[name] = pipeline&#10;&#10;        print(f&quot;{name} - RMSE: {rmse:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}&quot;)&#10;&#10;    # 选择最佳模型&#10;    best_model_name = min(results.keys(), key=lambda x: results[x]['RMSE'])&#10;    best_model = trained_models[best_model_name]&#10;&#10;    print(f&quot;\n最佳模型: {best_model_name}&quot;)&#10;&#10;    return results, trained_models, best_model, X_val_split, y_val_split&#10;&#10;def visualize_results(results, best_model, X_val, y_val):&#10;    &quot;&quot;&quot;可视化结果&quot;&quot;&quot;&#10;    print(&quot;生成可视化结果...&quot;)&#10;    &#10;    plt.figure(figsize=(15, 10))&#10;    &#10;    # 1. 模型性能比较 - RMSE&#10;    plt.subplot(2, 3, 1)&#10;    models = list(results.keys())&#10;    rmse_values = [results[m]['RMSE'] for m in models]&#10;    plt.bar(models, rmse_values, color='skyblue', alpha=0.7)&#10;    plt.title('模型RMSE比较')&#10;    plt.ylabel('RMSE')&#10;    plt.xticks(rotation=45)&#10;    for i, v in enumerate(rmse_values):&#10;        plt.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')&#10;    &#10;    # 2. 模型性能比较 - R²&#10;    plt.subplot(2, 3, 2)&#10;    r2_values = [results[m]['R2'] for m in models]&#10;    plt.bar(models, r2_values, color='lightgreen', alpha=0.7)&#10;    plt.title('模型R²比较')&#10;    plt.ylabel('R²')&#10;    plt.xticks(rotation=45)&#10;    for i, v in enumerate(r2_values):&#10;        plt.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')&#10;    &#10;    # 3. 预测vs实际&#10;    plt.subplot(2, 3, 3)&#10;    X_features, _, _ = prepare_features(X_val)&#10;    y_pred = best_model.predict(X_features)&#10;    plt.scatter(y_val, y_pred, alpha=0.6, color='blue')&#10;    plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)&#10;    plt.xlabel('实际评分')&#10;    plt.ylabel('预测评分')&#10;    plt.title('预测值 vs 实际值')&#10;    &#10;    # 4. 残差图&#10;    plt.subplot(2, 3, 4)&#10;    residuals = y_val - y_pred&#10;    plt.scatter(y_pred, residuals, alpha=0.6, color='green')&#10;    plt.axhline(y=0, color='r', linestyle='--')&#10;    plt.xlabel('预测评分')&#10;    plt.ylabel('残差')&#10;    plt.title('残差图')&#10;    &#10;    # 5. 损失对比&#10;    plt.subplot(2, 3, 5)&#10;    mae_values = [results[m]['MAE'] for m in models]&#10;    plt.bar(models, mae_values, color='orange', alpha=0.7)&#10;    plt.title('模型MAE比较')&#10;    plt.ylabel('MAE')&#10;    plt.xticks(rotation=45)&#10;    for i, v in enumerate(mae_values):&#10;        plt.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')&#10;    &#10;    # 6. 特征重要性&#10;    plt.subplot(2, 3, 6)&#10;    if hasattr(best_model.named_steps['model'], 'feature_importances_'):&#10;        importances = best_model.named_steps['model'].feature_importances_&#10;        feature_names = best_model.named_steps['preprocessor'].get_feature_names_out()&#10;        &#10;        # 选择前10个重要特征&#10;        indices = np.argsort(importances)[::-1][:10]&#10;        plt.barh(range(10), importances[indices])&#10;        plt.title('特征重要性 (Top 10)')&#10;        plt.yticks(range(10), [feature_names[i] for i in indices])&#10;    else:&#10;        plt.text(0.5, 0.5, '该模型无特征重要性', ha='center', va='center', &#10;                transform=plt.gca().transAxes)&#10;        plt.title('特征重要性')&#10;    &#10;    plt.tight_layout()&#10;    plt.savefig('model_evaluation.png', dpi=300, bbox_inches='tight')&#10;    plt.close()  # 关闭图形而不显示&#10;    print(&quot;可视化结果已保存为 model_evaluation.png&quot;)&#10;&#10;def predict_test_data(best_model, test_df):&#10;    &quot;&quot;&quot;预测测试数据&quot;&quot;&quot;&#10;    print(&quot;对测试数据进行预测...&quot;)&#10;&#10;    # 特征工程&#10;    test_df_processed = feature_engineering(test_df)&#10;    X_test_features, _, _ = prepare_features(test_df_processed)&#10;&#10;    # 预测&#10;    predictions = best_model.predict(X_test_features)&#10;&#10;    # 确保预测值在合理范围内&#10;    predictions = np.clip(predictions, 1, 10)&#10;&#10;    return predictions&#10;&#10;def main():&#10;    &quot;&quot;&quot;主函数&quot;&quot;&quot;&#10;    # 加载数据&#10;    train_df, test_df = load_data()&#10;&#10;    # 特征工程&#10;    train_df = feature_engineering(train_df)&#10;&#10;    # 准备训练数据&#10;    if 'rating' in train_df.columns:&#10;        X_train = train_df.drop('rating', axis=1)&#10;        y_train = train_df['rating']&#10;    else:&#10;        print(&quot;训练数据中没有rating列&quot;)&#10;        return&#10;&#10;    # 训练模型&#10;    results, trained_models, best_model, X_val, y_val = train_models(X_train, y_train)&#10;&#10;    # 可视化结果&#10;    visualize_results(results, best_model, X_val, y_val)&#10;&#10;    # 预测测试数据&#10;    predictions = predict_test_data(best_model, test_df)&#10;&#10;    # 保存结果&#10;    output_df = pd.DataFrame({&#10;        'id': test_df['id'] if 'id' in test_df.columns else range(len(test_df)),&#10;        'predicted_rating': predictions&#10;    })&#10;&#10;    output_df.to_csv('output_result/predicted_ratings.csv', index=False)&#10;&#10;    print(f&quot;\n预测完成！结果已保存到 output_result/predicted_ratings.csv&quot;)&#10;    print(f&quot;预测评分范围: {predictions.min():.2f} - {predictions.max():.2f}&quot;)&#10;    print(f&quot;预测评分均值: {predictions.mean():.2f}&quot;)&#10;    print(f&quot;预测评分标准差: {predictions.std():.2f}&quot;)&#10;&#10;    # 显示模型性能总结&#10;    print(&quot;\n=== 模型性能总结 ===&quot;)&#10;    for model_name, scores in results.items():&#10;        print(f&quot;{model_name}:&quot;)&#10;        print(f&quot;  RMSE: {scores['RMSE']:.4f}&quot;)&#10;        print(f&quot;  R²:   {scores['R2']:.4f}&quot;)&#10;        print(f&quot;  MAE:  {scores['MAE']:.4f}&quot;)&#10;        print()&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/predict.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/predict.py" />
              <option name="updatedContent" value="import pandas as pd&#10;import numpy as np&#10;import matplotlib.pyplot as plt&#10;import seaborn as sns&#10;from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor&#10;from sklearn.linear_model import Ridge&#10;from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV&#10;from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder&#10;from sklearn.compose import ColumnTransformer&#10;from sklearn.pipeline import Pipeline&#10;from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error&#10;import warnings&#10;warnings.filterwarnings('ignore')&#10;&#10;plt.rcParams['font.sans-serif'] = ['SimHei']&#10;plt.rcParams['axes.unicode_minus'] = False&#10;&#10;class MovieRatingPredictor:&#10;    def __init__(self):&#10;        self.model = None&#10;        self.preprocessor = None&#10;        self.feature_names = None&#10;        self.training_history = {}&#10;        &#10;    def load_and_preprocess_data(self, train_path, test_path):&#10;        &quot;&quot;&quot;加载和预处理数据&quot;&quot;&quot;&#10;        print(&quot;正在加载数据...&quot;)&#10;        &#10;        # 加载训练数据&#10;        try:&#10;            self.train_df = pd.read_csv(train_path)&#10;            print(f&quot;训练数据形状: {self.train_df.shape}&quot;)&#10;        except:&#10;            print(&quot;无法读取训练数据，尝试读取movie_features.npy&quot;)&#10;            # 如果CSV太大，尝试加载预处理的特征&#10;            features = np.load('movie_features.npy')&#10;            with open('feature_names.txt', 'r') as f:&#10;                feature_names = f.read().strip().split('\n')&#10;            self.train_df = pd.DataFrame(features, columns=feature_names)&#10;        &#10;        # 加载测试数据&#10;        self.test_df = pd.read_csv(test_path)&#10;        print(f&quot;测试数据形状: {self.test_df.shape}&quot;)&#10;        &#10;        # 特征工程&#10;        self.train_df = self._feature_engineering(self.train_df)&#10;        self.test_df = self._feature_engineering(self.test_df)&#10;        &#10;        return self.train_df, self.test_df&#10;    &#10;    def _feature_engineering(self, df):&#10;        &quot;&quot;&quot;特征工程&quot;&quot;&quot;&#10;        df = df.copy()&#10;        &#10;        # 处理类型特征&#10;        if 'genres' in df.columns:&#10;            df['main_genre'] = df['genres'].str.split(',').str[0]&#10;            df['genre_count'] = df['genres'].str.count(',') + 1&#10;        &#10;        # 处理演员特征&#10;        if 'cast' in df.columns:&#10;            df['cast_count'] = df['cast'].str.count(',') + 1&#10;            df['cast_count'] = df['cast_count'].fillna(0)&#10;        &#10;        # 处理导演特征&#10;        if 'director' in df.columns:&#10;            df['has_director'] = df['director'].notna().astype(int)&#10;        &#10;        # 处理编剧特征&#10;        if 'writers' in df.columns:&#10;            df['writers_count'] = df['writers'].str.count(',') + 1&#10;            df['writers_count'] = df['writers_count'].fillna(0)&#10;        &#10;        # 处理制片公司特征&#10;        if 'production_companies' in df.columns:&#10;            df['production_count'] = df['production_companies'].str.count(',') + 1&#10;            df['production_count'] = df['production_count'].fillna(0)&#10;        &#10;        # 处理语言特征&#10;        if 'original_language' in df.columns:&#10;            df['lang'] = df['original_language']&#10;        &#10;        # 处理时长特征&#10;        if 'runtime' in df.columns:&#10;            df['runtime'] = df['runtime'].fillna(df['runtime'].median())&#10;            df['runtime_category'] = pd.cut(df['runtime'], &#10;                                          bins=[0, 90, 120, 150, float('inf')],&#10;                                          labels=['短片', '标准', '长片', '超长'])&#10;        &#10;        return df&#10;    &#10;    def prepare_features(self, df, is_train=True):&#10;        &quot;&quot;&quot;准备特征&quot;&quot;&quot;&#10;        feature_columns = []&#10;        &#10;        # 数值特征&#10;        numeric_features = []&#10;        if 'runtime' in df.columns:&#10;            numeric_features.append('runtime')&#10;        if 'cast_count' in df.columns:&#10;            numeric_features.append('cast_count')&#10;        if 'writers_count' in df.columns:&#10;            numeric_features.append('writers_count')&#10;        if 'production_count' in df.columns:&#10;            numeric_features.append('production_count')&#10;        if 'genre_count' in df.columns:&#10;            numeric_features.append('genre_count')&#10;        if 'has_director' in df.columns:&#10;            numeric_features.append('has_director')&#10;            &#10;        # 类别特征&#10;        categorical_features = []&#10;        if 'main_genre' in df.columns:&#10;            categorical_features.append('main_genre')&#10;        if 'lang' in df.columns:&#10;            categorical_features.append('lang')&#10;        if 'runtime_category' in df.columns:&#10;            categorical_features.append('runtime_category')&#10;        &#10;        # 创建特征矩阵&#10;        features_df = pd.DataFrame()&#10;        &#10;        # 添加数值特征&#10;        for col in numeric_features:&#10;            if col in df.columns:&#10;                features_df[col] = df[col].fillna(0)&#10;        &#10;        # 添加类别特征&#10;        for col in categorical_features:&#10;            if col in df.columns:&#10;                features_df[col] = df[col].fillna('Unknown')&#10;        &#10;        return features_df, numeric_features, categorical_features&#10;    &#10;    def build_model(self):&#10;        &quot;&quot;&quot;构建模型&quot;&quot;&quot;&#10;        # 集成多个模型&#10;        models = {&#10;            'random_forest': RandomForestRegressor(&#10;                n_estimators=200,&#10;                max_depth=15,&#10;                min_samples_split=5,&#10;                min_samples_leaf=2,&#10;                random_state=42,&#10;                n_jobs=-1&#10;            ),&#10;            'gradient_boosting': GradientBoostingRegressor(&#10;                n_estimators=200,&#10;                learning_rate=0.1,&#10;                max_depth=6,&#10;                random_state=42&#10;            ),&#10;            'ridge': Ridge(alpha=1.0)&#10;        }&#10;        &#10;        return models&#10;    &#10;    def train_and_evaluate(self, X_train, y_train):&#10;        &quot;&quot;&quot;训练和评估模型&quot;&quot;&quot;&#10;        print(&quot;开始训练模型...&quot;)&#10;        &#10;        # 准备特征&#10;        X_features, numeric_features, categorical_features = self.prepare_features(X_train)&#10;        &#10;        # 创建预处理器&#10;        preprocessor = ColumnTransformer(&#10;            transformers=[&#10;                ('num', StandardScaler(), numeric_features),&#10;                ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)&#10;            ],&#10;            remainder='passthrough'&#10;        )&#10;        &#10;        # 构建模型&#10;        models = self.build_model()&#10;        &#10;        # 训练和验证每个模型&#10;        model_scores = {}&#10;        trained_models = {}&#10;        &#10;        # 分割训练和验证集&#10;        X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(&#10;            X_features, y_train, test_size=0.2, random_state=42&#10;        )&#10;        &#10;        for name, model in models.items():&#10;            print(f&quot;训练 {name}...&quot;)&#10;            &#10;            # 创建管道&#10;            pipeline = Pipeline([&#10;                ('preprocessor', preprocessor),&#10;                ('model', model)&#10;            ])&#10;            &#10;            # 训练模型&#10;            pipeline.fit(X_train_split, y_train_split)&#10;            &#10;            # 预测&#10;            y_pred = pipeline.predict(X_val_split)&#10;            &#10;            # 计算评分&#10;            mse = mean_squared_error(y_val_split, y_pred)&#10;            rmse = np.sqrt(mse)&#10;            mae = mean_absolute_error(y_val_split, y_pred)&#10;            r2 = r2_score(y_val_split, y_pred)&#10;            &#10;            model_scores[name] = {&#10;                'MSE': mse,&#10;                'RMSE': rmse,&#10;                'MAE': mae,&#10;                'R2': r2&#10;            }&#10;            &#10;            trained_models[name] = pipeline&#10;            &#10;            print(f&quot;{name} - RMSE: {rmse:.4f}, R2: {r2:.4f}&quot;)&#10;        &#10;        # 选择最佳模型&#10;        best_model_name = min(model_scores.keys(), key=lambda x: model_scores[x]['RMSE'])&#10;        self.model = trained_models[best_model_name]&#10;        self.preprocessor = self.model.named_steps['preprocessor']&#10;        &#10;        print(f&quot;最佳模型: {best_model_name}&quot;)&#10;        &#10;        return model_scores, trained_models&#10;    &#10;    def visualize_results(self, model_scores, X_val, y_val):&#10;        &quot;&quot;&quot;可视化结果&quot;&quot;&quot;&#10;        print(&quot;生成可视化结果...&quot;)&#10;        &#10;        # 1. 模型性能比较&#10;        plt.figure(figsize=(15, 10))&#10;        &#10;        # RMSE比较&#10;        plt.subplot(2, 3, 1)&#10;        models = list(model_scores.keys())&#10;        rmse_values = [model_scores[m]['RMSE'] for m in models]&#10;        plt.bar(models, rmse_values, color='skyblue')&#10;        plt.title('模型RMSE比较')&#10;        plt.ylabel('RMSE')&#10;        plt.xticks(rotation=45)&#10;        &#10;        # R2比较&#10;        plt.subplot(2, 3, 2)&#10;        r2_values = [model_scores[m]['R2'] for m in models]&#10;        plt.bar(models, r2_values, color='lightgreen')&#10;        plt.title('模型R²比较')&#10;        plt.ylabel('R²')&#10;        plt.xticks(rotation=45)&#10;        &#10;        # 预测vs实际&#10;        plt.subplot(2, 3, 3)&#10;        X_features, _, _ = self.prepare_features(X_val)&#10;        y_pred = self.model.predict(X_features)&#10;        plt.scatter(y_val, y_pred, alpha=0.6)&#10;        plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)&#10;        plt.xlabel('实际评分')&#10;        plt.ylabel('预测评分')&#10;        plt.title('预测值 vs 实际值')&#10;        &#10;        # 残差图&#10;        plt.subplot(2, 3, 4)&#10;        residuals = y_val - y_pred&#10;        plt.scatter(y_pred, residuals, alpha=0.6)&#10;        plt.axhline(y=0, color='r', linestyle='--')&#10;        plt.xlabel('预测评分')&#10;        plt.ylabel('残差')&#10;        plt.title('残差图')&#10;        &#10;        # 损失历史（如果有的话）&#10;        plt.subplot(2, 3, 5)&#10;        if hasattr(self.model.named_steps['model'], 'train_score_'):&#10;            train_scores = self.model.named_steps['model'].train_score_&#10;            plt.plot(train_scores, label='训练损失')&#10;            plt.xlabel('迭代次数')&#10;            plt.ylabel('损失')&#10;            plt.title('训练损失曲线')&#10;            plt.legend()&#10;        else:&#10;            plt.text(0.5, 0.5, '该模型无训练历史', ha='center', va='center', transform=plt.gca().transAxes)&#10;        &#10;        # 特征重要性（如果是树模型）&#10;        plt.subplot(2, 3, 6)&#10;        if hasattr(self.model.named_steps['model'], 'feature_importances_'):&#10;            importances = self.model.named_steps['model'].feature_importances_&#10;            feature_names = self.preprocessor.get_feature_names_out()&#10;            &#10;            # 选择前10个重要特征&#10;            indices = np.argsort(importances)[::-1][:10]&#10;            plt.bar(range(10), importances[indices])&#10;            plt.title('特征重要性 (Top 10)')&#10;            plt.xticks(range(10), [feature_names[i] for i in indices], rotation=45)&#10;        else:&#10;            plt.text(0.5, 0.5, '该模型无特征重要性', ha='center', va='center', transform=plt.gca().transAxes)&#10;        &#10;        plt.tight_layout()&#10;        plt.savefig('model_evaluation.png', dpi=300, bbox_inches='tight')&#10;        plt.show()&#10;    &#10;    def predict_test_data(self, test_df):&#10;        &quot;&quot;&quot;预测测试数据&quot;&quot;&quot;&#10;        print(&quot;对测试数据进行预测...&quot;)&#10;        &#10;        X_test_features, _, _ = self.prepare_features(test_df, is_train=False)&#10;        predictions = self.model.predict(X_test_features)&#10;        &#10;        # 创建结果DataFrame&#10;        result_df = test_df.copy()&#10;        result_df['predicted_rating'] = predictions&#10;        &#10;        return result_df, predictions&#10;&#10;def main():&#10;    &quot;&quot;&quot;主函数&quot;&quot;&quot;&#10;    predictor = MovieRatingPredictor()&#10;    &#10;    # 加载数据&#10;    train_df, test_df = predictor.load_and_preprocess_data(&#10;        'df_movies_cleaned.csv',&#10;        'input_data/df_movies_test.csv'&#10;    )&#10;    &#10;    # 准备训练数据&#10;    if 'rating' in train_df.columns:&#10;        X_train = train_df.drop('rating', axis=1)&#10;        y_train = train_df['rating']&#10;    else:&#10;        print(&quot;警告: 训练数据中未找到'rating'列，尝试使用所有特征...&quot;)&#10;        X_train = train_df&#10;        # 生成模拟的评分用于演示（实际使用时请删除）&#10;        y_train = np.random.normal(7.0, 1.5, len(train_df))&#10;        y_train = np.clip(y_train, 0, 10)&#10;    &#10;    # 训练模型&#10;    model_scores, trained_models = predictor.train_and_evaluate(X_train, y_train)&#10;    &#10;    # 创建验证集用于可视化&#10;    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(&#10;        X_train, y_train, test_size=0.2, random_state=42&#10;    )&#10;    &#10;    # 可视化结果&#10;    predictor.visualize_results(model_scores, X_val_split, y_val_split)&#10;    &#10;    # 预测测试数据&#10;    result_df, predictions = predictor.predict_test_data(test_df)&#10;    &#10;    # 保存结果&#10;    output_df = pd.DataFrame({&#10;        'id': test_df['id'] if 'id' in test_df.columns else range(len(test_df)),&#10;        'predicted_rating': predictions&#10;    })&#10;    &#10;    output_df.to_csv('output_result/predicted_ratings.csv', index=False)&#10;    &#10;    print(f&quot;预测完成！结果已保存到 output_result/predicted_ratings.csv&quot;)&#10;    print(f&quot;预测评分范围: {predictions.min():.2f} - {predictions.max():.2f}&quot;)&#10;    print(f&quot;预测评分均值: {predictions.mean():.2f}&quot;)&#10;    &#10;    # 显示模型性能总结&#10;    print(&quot;\n=== 模型性能总结 ===&quot;)&#10;    for model_name, scores in model_scores.items():&#10;        print(f&quot;{model_name}:&quot;)&#10;        print(f&quot;  RMSE: {scores['RMSE']:.4f}&quot;)&#10;        print(f&quot;  R²:   {scores['R2']:.4f}&quot;)&#10;        print(f&quot;  MAE:  {scores['MAE']:.4f}&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>