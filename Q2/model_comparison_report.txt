# 电影评分预测模型比较报告

## 任务背景

电影评分预测是一个典型的回归任务，需要基于电影的各种特征（如类型、演员、导演、时长等）预测其评分。这类任务的挑战在于：
1. **特征复杂性**: 文本特征（演员、导演名字）需要编码
2. **非线性关系**: 评分与特征间可能存在复杂的非线性关系
3. **数据稀疏性**: 某些特征组合可能很少出现
4. **评分分布**: 评分通常呈现特定的分布模式

## 模型详细分析

### 1. Linear Regression（线性回归）
**原理**: 假设目标变量与特征之间存在线性关系，通过最小化均方误差来学习线性系数。
```
y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε
```
**工作机制**:
- 使用最小二乘法求解: (X^T X)^(-1) X^T y
- 假设特征与目标呈线性关系
- 对异常值敏感

**优点**: 简单快速，可解释性强
**缺点**: 假设过于简化，无法捕捉非线性关系
**适用场景**: 特征与目标线性相关时

### 2. Ridge Regression（岭回归）
**原理**: 在线性回归基础上加入L2正则化项，防止过拟合。
```
损失函数 = MSE + α∑βᵢ²
```
**工作机制**:
- L2正则化惩罚大的系数，使模型更稳定
- α参数控制正则化强度
- 通过岭估计求解: (X^T X + αI)^(-1) X^T y

**优点**: 解决多重共线性，防止过拟合
**缺点**: 仍然是线性模型，不能处理复杂非线性关系
**适用场景**: 特征间存在多重共线性时

### 3. Random Forest（随机森林）
**原理**: 基于Bagging的集成学习，训练多个决策树并平均预测结果。
**工作机制**:
- **Bootstrap采样**: 每棵树用不同的训练子集
- **特征随机性**: 每次分裂时随机选择特征子集
- **预测**: 所有树预测的平均值
```
预测 = (1/n) ∑ᵢ₌₁ⁿ Treeᵢ(x)
```

**树构建过程**:
1. 随机抽样构建训练集
2. 在每个节点随机选择特征子集
3. 选择最佳分裂特征和阈值
4. 递归构建子树直到停止条件

**优点**: 
- 能处理非线性关系
- 对异常值鲁棒
- 提供特征重要性
- 不容易过拟合

**缺点**: 
- 模型复杂度高
- 对噪声敏感
- 可解释性较差

### 4. Gradient Boosting（梯度提升）
**原理**: 串行训练弱学习器，每个新模型都试图修正前面模型的错误。
**工作机制**:
- **顺序学习**: 模型按序训练，后面的模型关注前面模型的错误
- **梯度下降**: 在函数空间中进行梯度下降优化
```
F₀(x) = 初始预测
Fₘ(x) = Fₘ₋₁(x) + γₘhₘ(x)
```

**训练过程**:
1. 初始化F₀(x)为常数（通常是均值）
2. 对m=1到M:
   - 计算残差: rᵢₘ = -[∂L(yᵢ,F(xᵢ))/∂F(xᵢ)]
   - 训练弱学习器hₘ拟合残差
   - 更新模型: Fₘ = Fₘ₋₁ + γₘhₘ

**优点**: 
- 强大的非线性建模能力
- 逐步减少偏差
- 性能通常很好

**缺点**: 
- 容易过拟合
- 训练时间较长
- 超参数敏感

### 5. Support Vector Regression（支持向量回归）
**原理**: 寻找一个超平面，使得大部分数据点都在ε-管内，同时最大化边界。
**工作机制**:
- **ε-不敏感损失**: 只有误差超过ε才计算损失
- **核技巧**: 通过核函数映射到高维空间处理非线性
- **支持向量**: 只有边界上的点（支持向量）影响模型

**数学表示**:
```
f(x) = ∑ᵢ(αᵢ - αᵢ*)K(xᵢ, x) + b
```
其中K(xᵢ, x)是核函数

**优化目标**:
```
min: (1/2)||w||² + C∑ᵢ(ξᵢ + ξᵢ*)
约束: |yᵢ - f(xᵢ)| ≤ ε + ξᵢ
```

**核函数选择**:
- **线性核**: K(x,x') = x·x'
- **RBF核**: K(x,x') = exp(-γ||x-x'||²)  ←本次使用
- **多项式核**: K(x,x') = (x·x'+1)ᵈ

**优点**: 
- 强大的非线性建模能力（通过核函数）
- 对高维数据有效
- 泛化能力强
- 对异常值鲁棒（ε-不敏感）

**缺点**: 
- 训练时间较长（O(n³)）
- 超参数选择重要
- 内存消耗大

### 6. Neural Network（神经网络）
**原理**: 多层感知机，通过多层非线性变换学习复杂模式。
**工作机制**:
- **前向传播**: 输入通过多层神经元传播到输出
- **反向传播**: 通过梯度下降更新权重
- **激活函数**: 引入非线性（如ReLU、Sigmoid）

**网络结构**:
```
输入层 → 隐藏层1 → 隐藏层2 → ... → 输出层
```

**训练过程**:
1. 前向传播计算预测值
2. 计算损失函数
3. 反向传播计算梯度
4. 更新权重参数

**优点**: 
- 极强的非线性建模能力
- 自动特征学习
- 可处理复杂模式

**缺点**: 
- 需要大量数据
- 训练时间很长
- 容易过拟合
- 黑盒模型，可解释性差

## 为什么选择Support Vector Regression？

## 性能比较

- **准确性最佳**: Support Vector Regression (RMSE: 1.5178)
- **拟合最佳**: Support Vector Regression (R²: 0.1374)
- **速度最快**: Ridge Regression (时间: 0.03秒)

================================================================================
详细模型比较结果
================================================================================
模型名称                 RMSE     MAE      R²       MAPE     训练时间
--------------------------------------------------------------------------------
Support Vector Regression 1.5178   1.1238   0.1374   27.2    % 2.07      s
Random Forest        1.5348   1.1468   0.1180   27.5    % 0.22      s
Ridge Regression     1.5365   1.1392   0.1160   27.4    % 0.03      s
Linear Regression    1.5376   1.1399   0.1148   27.4    % 0.11      s
Gradient Boosting    1.5467   1.1492   0.1043   27.3    % 1.89      s
Neural Network       1.6110   1.2102   0.0282   28.3    % 21.21     s

## 建议

- 模型表现有待提升，建议进行更多特征工程或使用深度学习